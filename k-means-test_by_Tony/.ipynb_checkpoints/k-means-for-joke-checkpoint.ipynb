{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class store the internsity and pitch \n",
    "class Pause_Info:\n",
    "  def __init__(self,intensity,stinten,pitch,stpit,max_inten,min_inten,max_pitch,min_pitch,performance,id,jokeName):\n",
    "    self.intensity = intensity\n",
    "    self.stinten= stinten\n",
    "    self.pitch = pitch\n",
    "    self.stpit= stpit\n",
    "    self.max_inten=max_inten\n",
    "    self.min_inten=min_inten\n",
    "    self.max_pitch=max_pitch\n",
    "    self.min_pitch=min_pitch\n",
    "    self.performance=performance\n",
    "    self.id=id\n",
    "    self.jokeName=jokeName\n",
    "    \n",
    "    \n",
    "#this function loop through the folder \"joke_name_matching\" and make a dictionary of \n",
    "#joke id and joke name for each performance\n",
    "def getJokeNameForEachPerformance(folderPath):\n",
    "    os.chdir(folderPath)\n",
    "    \n",
    "    jokeNameDict={}\n",
    "    \n",
    "    for file in glob.glob(\"*.txt\"):\n",
    "        idDict={}\n",
    "        filepath=folderPath+'\\\\'+file\n",
    "        f = open(filepath, \"r\")\n",
    "        key=f.readline()\n",
    "        key=key.replace(\"\\x00\",\"\")\n",
    "        key=key.replace(\"\\n\",\"\")\n",
    "#         print(key)\n",
    "        content=f.read();\n",
    "        f.close()\n",
    "        content=content.replace(\"\\x00\",\"\")\n",
    "        content=content.replace(\"\\n\\n\",\"\\n\")\n",
    "        if not content:\n",
    "            continue\n",
    "        lines=content.split('\\n')\n",
    "        lines.pop(0)\n",
    "        lines.pop(-1)\n",
    "        for line in lines:\n",
    "            jokename=line.split(':')[0]\n",
    "            id=int(line.split(':')[1].split('.')[0].split('_')[1])\n",
    "#             print(jokename,id)\n",
    "            idDict[id]=jokename\n",
    "        jokeNameDict[key]=idDict\n",
    "    \n",
    "    return jokeNameDict\n",
    "            \n",
    "\n",
    "#This function extract intensity and pitch info from txt file and put all info in to a dictionary\n",
    "def readTxT(path):\n",
    "    f = open(path, \"r\")\n",
    "    line = f.readline()\n",
    "    \n",
    "    #store the joke title\n",
    "    Title = line.split('\\\\')[-2]\n",
    "    Title=Title.replace(\"\\x00\",\"\")\n",
    "    joke_dict = {}\n",
    "\n",
    "    content=f.read();\n",
    "    f.close()\n",
    "    \n",
    "    #replace all these werid \\x00 in python\n",
    "    #also replace all the extra newline char\n",
    "    content=content.replace(\"\\x00\",\"\")\n",
    "    content=content.replace(\"\\n\\n\",\"\\n\")\n",
    "    lines=content.split('\\n')\n",
    "    \n",
    "    #remove the first and last extra new line char\n",
    "    lines.pop(0)\n",
    "    lines.pop(-1)\n",
    "\n",
    "    count=0\n",
    "    intensity=0\n",
    "    stinten=0\n",
    "    pitch=0\n",
    "    stpit=0\n",
    "    max_inten=0\n",
    "    min_inten=0\n",
    "    max_pitch=0\n",
    "    min_pitch=0\n",
    "    digits=2\n",
    "    \n",
    "    #store 7 info of each audio\n",
    "    for line in lines:\n",
    "        if(count%9==0):\n",
    "            name=line.split('.')[0]\n",
    "            name=name.split('_')[-1]\n",
    "            id=int(name)\n",
    "        elif(count%9==1):\n",
    "            intensity=round(float(line),digits)\n",
    "        elif(count%9==2):\n",
    "            stinten=round(float(line),digits)\n",
    "        elif(count%9==3):\n",
    "            min_inten=round(float(line),digits)\n",
    "        elif(count%9==4):\n",
    "            max_inten=round(float(line),digits)\n",
    "        elif(count%9==5):\n",
    "            pitch=round(float(line),digits)\n",
    "        elif(count%9==6):\n",
    "            stpit=round(float(line),digits)   \n",
    "        elif(count%9==7):\n",
    "            max_pitch=round(float(line),digits)\n",
    "        else:\n",
    "            min_pitch=round(float(line),digits)\n",
    "            if(Title not in jokeNameDict):\n",
    "                break\n",
    "            idDict=jokeNameDict[Title]\n",
    "            jokeName=idDict[id]\n",
    "            #print(jokeName)\n",
    "            joke_dict[jokeName]=Pause_Info(intensity,stinten,pitch,stpit,max_inten,min_inten,max_pitch,min_pitch,Title,id,jokeName)\n",
    "           # print(Title,id)\n",
    "        count+=1\n",
    "    return joke_dict\n",
    "\n",
    "\n",
    "import glob, os\n",
    "\n",
    "\n",
    "\n",
    "#in combine_joke_dict,\n",
    "#key of combine_joke_dict represent the joke id\n",
    "#value of combine_joke_dict is an array of 'Pause_Info' who are the same joke but in different perofrmance\n",
    "#len of value represent how many different perofrmance contain this joke \n",
    "def findAlltxtAndCombine(folderPath):\n",
    "    os.chdir(folderPath)\n",
    "    combine_joke_dict={}\n",
    "    \n",
    "    #find all txt file inside folder\n",
    "    for file in glob.glob(\"*.txt\"):\n",
    "        filepath=folderPath+'\\\\'+file\n",
    "        single_joke_dict=readTxT(filepath)   \n",
    "        for x in single_joke_dict:\n",
    "            y=single_joke_dict[x]\n",
    "            if x in combine_joke_dict:\n",
    "                combine_joke_dict[x].append(y)\n",
    "            else:\n",
    "                combine_joke_dict[x]=[y]\n",
    "    return combine_joke_dict         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import scale\n",
    "from numpy import random, float\n",
    "# plt.rcParams['font.sans-serif']=['SimHei']\n",
    "# plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "#info_arr represent an array of same joke in different performances\n",
    "#choice=1 is using intensity and pitch as x-y axis\n",
    "#choice=2 is using std intensity and std pitch as x-y axis\n",
    "def clusterDataIn2D(Info_arr,choice):\n",
    "    jokeid=Info_arr[0].jokeName.replace('/','-')\n",
    "    data=[]\n",
    "    x=[]\n",
    "    y=[]\n",
    "    performanceName=[]\n",
    "    Xname,Yname='',''\n",
    "    if(choice==1):\n",
    "        for joke in Info_arr:\n",
    "            X=joke.intensity\n",
    "            Y=joke.pitch\n",
    "            data.append((X,Y))\n",
    "            performanceName.append(joke.performance)\n",
    "            x.append(X)\n",
    "            y.append(Y)\n",
    "            Xname=\"intensity\"\n",
    "            Yname=\"pitch\"\n",
    "    elif(choice==2):\n",
    "        for joke in Info_arr:\n",
    "            X=joke.stinten\n",
    "            Y=joke.stpit\n",
    "            data.append((X,Y))\n",
    "            performanceName.append(joke.performance)\n",
    "            x.append(X)\n",
    "            y.append(Y)\n",
    "            Xname=\"standard deviation intensity\"\n",
    "            Yname=\"standard deviation pitch\"\n",
    "    \n",
    "    #if the data set is smller than 2,we will ignore it.\n",
    "    if(len(data)<2):\n",
    "        return \n",
    "        \n",
    "    # spilt them into 2 group\n",
    "        \n",
    "    model = KMeans(n_clusters=2)\n",
    "\n",
    "    # Note I'm scaling the data to normalize it! Important for good results.\n",
    "    model = model.fit(scale(data))\n",
    "\n",
    "    # We can look at the clusters each data point was assigned to\n",
    "\n",
    "    \n",
    "    count=0\n",
    "    Group0=[]\n",
    "    Group1=[]\n",
    "    for i in data:\n",
    "        #print(\"performance Name: \"+str(performanceName[count])+\"\\t\",\"Data values: \"+str(i)+\"\\t\",\"Group ID: \"+str(model.labels_[count]))  \n",
    "        if(model.labels_[count]==0):\n",
    "            Group0.append((performanceName[count],str(i)))\n",
    "        else:\n",
    "            Group1.append((performanceName[count],str(i)))\n",
    "        count+=1\n",
    "\n",
    "    dataTitle=\"Data values: (\"+Xname+\",\"+Yname+\")\\n\"\n",
    "    Group0txt=\"Group0\\n\"\n",
    "    Group1txt=\"Group1\\n\"\n",
    "    for a in Group0:\n",
    "        Group0txt=Group0txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "        \n",
    "    for a in Group1:\n",
    "        Group1txt=Group1txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "\n",
    "    \n",
    "    p=os.getcwd()\n",
    "    \n",
    "    \n",
    "    #save all info into txt\n",
    "    #print(jokeid)\n",
    "    txtName=\"../jokeoutput/2D/\"+str(jokeid)+\".txt\"\n",
    "\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(dataTitle+Group0txt+Group1txt)\n",
    "    f.close()\n",
    "    \n",
    "#     print(jokeid)\n",
    "#     print (model.cluster_centers_)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(x, y, c=model.labels_.astype(float))\n",
    "    plt.title(\"Joke Name: \"+str(jokeid))\n",
    "    plt.xlabel(Xname)\n",
    "    plt.ylabel(Yname)\n",
    "    \n",
    "    pngName=\"../jokeoutput/2D/\"+str(jokeid)+\".png\"\n",
    "    \n",
    "    #remove the existing png file\n",
    "    if os.path.isfile(pngName):\n",
    "        os.remove(pngName) \n",
    "    \n",
    "    #save as png file\n",
    "    plt.savefig(pngName)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#this function will split data into 2 groups by using 4 features\n",
    "def clusterDataIn4D(Info_arr):\n",
    "    #replace all the '/' to '-' since it will mess up with path of windows\n",
    "    jokeid=Info_arr[0].jokeName.replace('/','-')\n",
    "    data=[]\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    h=[]\n",
    "    performanceName=[]\n",
    "    Xname,Yname='',''\n",
    "    \n",
    "    #get all intensity,pitch,std intensity,std pitch\n",
    "    for joke in Info_arr:\n",
    "        X=joke.intensity\n",
    "        Y=joke.pitch\n",
    "        Z=joke.stinten\n",
    "        H=joke.stpit\n",
    "        data.append((X,Y,Z,H))\n",
    "        performanceName.append(joke.performance)\n",
    "        x.append(X)\n",
    "        y.append(Y)\n",
    "        z.append(Z)\n",
    "        h.append(H)\n",
    "        Xname=\"intensity\"\n",
    "        Yname=\"pitch\"\n",
    "        Zname=\"std intensity\"\n",
    "        Hname=\"std pitch\"\n",
    "\n",
    "    \n",
    "    #if data set is smaller than 2, we cannot split them into 2groups\n",
    "    if(len(data)<2):\n",
    "        return \n",
    "        \n",
    "    # spilt them into 2 group\n",
    "        \n",
    "    model = KMeans(n_clusters=2)\n",
    "\n",
    "    # Note I'm scaling the data to normalize it! Important for good results.\n",
    "    model = model.fit(scale(data))\n",
    "\n",
    "    # We can look at the clusters each data point was assigned to\n",
    "\n",
    "    \n",
    "    count=0\n",
    "    Group0=[]\n",
    "    Group1=[]\n",
    "    for i in data:\n",
    "        #print(\"performance Name: \"+str(performanceName[count])+\"\\t\",\"Data values: \"+str(i)+\"\\t\",\"Group ID: \"+str(model.labels_[count]))  \n",
    "        if(model.labels_[count]==0):\n",
    "            Group0.append((performanceName[count],str(i)))\n",
    "        else:\n",
    "            Group1.append((performanceName[count],str(i)))\n",
    "        count+=1\n",
    "    \n",
    "    dataTitle=\"Data values: (\"+Xname+\",\"+Yname+\",\"+Zname+\",\"+Hname+\")\\n\"\n",
    "    Group0txt=\"Group0\\n\"\n",
    "    Group1txt=\"Group1\\n\"\n",
    "    for a in Group0:\n",
    "        Group0txt=Group0txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "        \n",
    "    for a in Group1:\n",
    "        Group1txt=Group1txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "\n",
    "    \n",
    "    p=os.getcwd()\n",
    "    \n",
    "    \n",
    "    #save all info into txt\n",
    "    txtName=\"../jokeoutput/4D/\"+str(jokeid)+\".txt\"\n",
    "\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(dataTitle+Group0txt+Group1txt)\n",
    "    f.close()\n",
    "    \n",
    "#     print(jokeid)\n",
    "#     print (model.cluster_centers_)\n",
    "\n",
    "\n",
    "#this function will split data into 2 groups by using 6 features\n",
    "def clusterDataIn8D(Info_arr):\n",
    "    #replace all the '/' to '-' since it will mess up with path of windows\n",
    "    jokeid=Info_arr[0].jokeName.replace('/','-')\n",
    "    data=[]\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    d=[]\n",
    "    e=[]\n",
    "    f=[]\n",
    "    g=[]\n",
    "    h=[]\n",
    "    performanceName=[]\n",
    "    Xname,Yname='',''\n",
    "    \n",
    "    #get all intensity,pitch,std intensity,std pitch\n",
    "    for joke in Info_arr:\n",
    "        X=joke.intensity\n",
    "        Y=joke.pitch\n",
    "        Z=joke.stinten\n",
    "        D=joke.stpit\n",
    "        E=joke.max_inten\n",
    "        F=joke.min_inten\n",
    "        G=joke.max_pitch\n",
    "        H=joke.min_pitch\n",
    " \n",
    "        data.append((X,Y,Z,D,E,F,G,H))\n",
    "        performanceName.append(joke.performance+\"----Joke ID: \"+str(joke.id))\n",
    "        x.append(X)\n",
    "        y.append(Y)\n",
    "        z.append(Z)\n",
    "        d.append(d)\n",
    "        e.append(E)\n",
    "        f.append(F)\n",
    "        g.append(G)\n",
    "        h.append(H)\n",
    "        \n",
    "        \n",
    "#         print(E,F)\n",
    "        \n",
    "        Xname=\"intensity\"\n",
    "        Yname=\"pitch\"\n",
    "        Zname=\"std intensity\"\n",
    "        Dname=\"std pitch\"\n",
    "        Ename=\"max inten\"\n",
    "        Fname=\"min inten\"\n",
    "        Gname=\"max pitch\"\n",
    "        Hname=\"min pitch\"\n",
    "\n",
    "    \n",
    "    #if data set is smaller than 2, we cannot split them into 2groups\n",
    "    if(len(data)<2):\n",
    "        return \n",
    "        \n",
    "    # spilt them into 2 group\n",
    "        \n",
    "    model = KMeans(n_clusters=2)\n",
    "\n",
    "    # Note I'm scaling the data to normalize it! Important for good results.\n",
    "    model = model.fit(scale(data))\n",
    "\n",
    "    # We can look at the clusters each data point was assigned to\n",
    "\n",
    "    \n",
    "    count=0\n",
    "    Group0=[]\n",
    "    Group1=[]\n",
    "    for i in data:\n",
    "        #print(\"performance Name: \"+str(performanceName[count])+\"\\t\",\"Data values: \"+str(i)+\"\\t\",\"Group ID: \"+str(model.labels_[count]))  \n",
    "        if(model.labels_[count]==0):\n",
    "            Group0.append((performanceName[count],str(i)))\n",
    "        else:\n",
    "            Group1.append((performanceName[count],str(i)))\n",
    "        count+=1\n",
    "    \n",
    "    dataTitle=\"Data values: (\"+Xname+\",\"+Yname+\",\"+Zname+\",\"+Dname+\",\"+Ename+\",\"+Fname+\",\"+Gname+\",\"+Hname+\")\\n\"\n",
    "    Group0txt=\"Group0\\n\"\n",
    "    Group1txt=\"Group1\\n\"\n",
    "    for a in Group0:\n",
    "        Group0txt=Group0txt+\"performance Name and Joke ID: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "        \n",
    "    for a in Group1:\n",
    "        Group1txt=Group1txt+\"performance Name and Joke ID: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "\n",
    "    \n",
    "    p=os.getcwd()\n",
    "    \n",
    "    \n",
    "    #save all info into txt\n",
    "    txtName=\"../jokeoutput/8D/\"+str(jokeid)+\".txt\"\n",
    "\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(dataTitle+Group0txt+Group1txt)\n",
    "    f.close()\n",
    "    \n",
    "#     print(jokeid)\n",
    "#     print (model.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 Cienna Nerdy Show at The Drake 0\n",
      "2019-09-05 Stand-up Science 0\n",
      "2019-09-06 RoboCom 0\n",
      "2019-09-19 Bombs Away Cafe 0\n",
      "2019-09-21 Laugh Track Town USA 0\n",
      "2019-10-11 Singu-hilarity 0\n",
      "2019-11-29 Comedy the Musical 0\n",
      "2019-11-29 Crapshoot 0\n",
      "2019-12-06 Silent Background Recording 0\n",
      "2019-04-18 Bombs Away Cafe 0\n",
      "2019-04-19 Singu-hilarity 0\n",
      "2019-04-22 Class Performance 0\n",
      "2019-05-16 Bombs Away Cafe 0\n",
      "2019-06-19 Trek Theater 0\n",
      "2019-06-20 Bombs Away Cafe 0\n",
      "2019-08-15 Bombs Away Cafe 0\n",
      "2019-08-23 Spectrum 0\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 1\n",
      "2019-09-05 Stand-up Science 1\n",
      "2019-09-06 RoboCom 1\n",
      "2019-09-21 Laugh Track Town USA 1\n",
      "2019-10-11 Singu-hilarity 1\n",
      "2019-11-29 Comedy the Musical 1\n",
      "2019-11-29 Crapshoot 1\n",
      "2019-12-06 Silent Background Recording 1\n",
      "2019-04-19 Singu-hilarity 1\n",
      "2019-04-22 Class Performance 1\n",
      "2019-05-16 Bombs Away Cafe 1\n",
      "2019-06-19 Trek Theater 1\n",
      "2019-08-15 Bombs Away Cafe 1\n",
      "2019-08-23 Spectrum 1\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 10\n",
      "2019-09-06 RoboCom 12\n",
      "2019-08-15 Bombs Away Cafe 10\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 11\n",
      "2019-09-05 Stand-up Science 8\n",
      "2019-09-06 RoboCom 13\n",
      "2019-09-19 Bombs Away Cafe 3\n",
      "2019-09-21 Laugh Track Town USA 6\n",
      "2019-10-11 Singu-hilarity 6\n",
      "2019-11-29 Comedy the Musical 4\n",
      "2019-11-29 Crapshoot 4\n",
      "2019-12-06 Silent Background Recording 13\n",
      "2019-04-18 Bombs Away Cafe 3\n",
      "2019-04-19 Singu-hilarity 13\n",
      "2019-04-22 Class Performance 9\n",
      "2019-05-16 Bombs Away Cafe 4\n",
      "2019-06-19 Trek Theater 8\n",
      "2019-08-15 Bombs Away Cafe 11\n",
      "2019-08-23 Spectrum 8\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 12\n",
      "2019-09-06 RoboCom 14\n",
      "2019-09-19 Bombs Away Cafe 4\n",
      "2019-10-11 Singu-hilarity 7\n",
      "2019-11-29 Comedy the Musical 5\n",
      "2019-11-29 Crapshoot 5\n",
      "2019-04-18 Bombs Away Cafe 4\n",
      "2019-04-19 Singu-hilarity 14\n",
      "2019-04-22 Class Performance 10\n",
      "2019-08-15 Bombs Away Cafe 12\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 13\n",
      "2019-09-05 Stand-up Science 9\n",
      "2019-09-06 RoboCom 16\n",
      "2019-09-19 Bombs Away Cafe 7\n",
      "2019-09-21 Laugh Track Town USA 8\n",
      "2019-10-11 Singu-hilarity 10\n",
      "2019-11-29 Comedy the Musical 8\n",
      "2019-11-29 Crapshoot 8\n",
      "2019-12-06 Silent Background Recording 16\n",
      "2019-04-19 Singu-hilarity 15\n",
      "2019-04-22 Class Performance 11\n",
      "2019-06-19 Trek Theater 9\n",
      "2019-08-15 Bombs Away Cafe 13\n",
      "2019-08-23 Spectrum 9\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 14\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 15\n",
      "2019-09-05 Stand-up Science 10\n",
      "2019-09-06 RoboCom 17\n",
      "2019-12-06 Silent Background Recording 18\n",
      "2019-04-19 Singu-hilarity 17\n",
      "2019-04-22 Class Performance 13\n",
      "2019-06-19 Trek Theater 10\n",
      "2019-08-15 Bombs Away Cafe 15\n",
      "2019-08-23 Spectrum 10\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 16\n",
      "2019-09-05 Stand-up Science 11\n",
      "2019-09-06 RoboCom 18\n",
      "2019-12-06 Silent Background Recording 19\n",
      "2019-04-19 Singu-hilarity 18\n",
      "2019-04-22 Class Performance 14\n",
      "2019-06-19 Trek Theater 11\n",
      "2019-08-15 Bombs Away Cafe 16\n",
      "2019-08-23 Spectrum 11\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 17\n",
      "2019-09-05 Stand-up Science 12\n",
      "2019-09-06 RoboCom 19\n",
      "2019-12-06 Silent Background Recording 20\n",
      "2019-04-19 Singu-hilarity 19\n",
      "2019-04-22 Class Performance 15\n",
      "2019-06-19 Trek Theater 12\n",
      "2019-08-15 Bombs Away Cafe 17\n",
      "2019-08-23 Spectrum 12\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 18\n",
      "2019-09-05 Stand-up Science 13\n",
      "2019-09-06 RoboCom 20\n",
      "2019-12-06 Silent Background Recording 21\n",
      "2019-04-19 Singu-hilarity 20\n",
      "2019-04-22 Class Performance 16\n",
      "2019-06-19 Trek Theater 13\n",
      "2019-08-15 Bombs Away Cafe 18\n",
      "2019-08-23 Spectrum 13\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 19\n",
      "2019-09-06 RoboCom 21\n",
      "2019-12-06 Silent Background Recording 22\n",
      "2019-04-19 Singu-hilarity 21\n",
      "2019-04-22 Class Performance 17\n",
      "2019-08-15 Bombs Away Cafe 19\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 2\n",
      "2019-09-06 RoboCom 2\n",
      "2019-09-21 Laugh Track Town USA 2\n",
      "2019-10-11 Singu-hilarity 2\n",
      "2019-11-29 Comedy the Musical 2\n",
      "2019-11-29 Crapshoot 2\n",
      "2019-04-19 Singu-hilarity 2\n",
      "2019-04-22 Class Performance 2\n",
      "2019-08-15 Bombs Away Cafe 2\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 20\n",
      "2019-09-05 Stand-up Science 14\n",
      "2019-09-06 RoboCom 22\n",
      "2019-12-06 Silent Background Recording 23\n",
      "2019-04-19 Singu-hilarity 22\n",
      "2019-06-19 Trek Theater 14\n",
      "2019-08-15 Bombs Away Cafe 20\n",
      "2019-08-23 Spectrum 14\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 21\n",
      "2019-09-05 Stand-up Science 15\n",
      "2019-09-06 RoboCom 27\n",
      "2019-09-21 Laugh Track Town USA 14\n",
      "2019-10-11 Singu-hilarity 16\n",
      "2019-12-06 Silent Background Recording 28\n",
      "2019-04-18 Bombs Away Cafe 10\n",
      "2019-04-19 Singu-hilarity 23\n",
      "2019-04-22 Class Performance 18\n",
      "2019-06-19 Trek Theater 15\n",
      "2019-08-15 Bombs Away Cafe 21\n",
      "2019-08-23 Spectrum 15\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 22\n",
      "2019-04-18 Bombs Away Cafe 11\n",
      "2019-04-19 Singu-hilarity 24\n",
      "2019-08-15 Bombs Away Cafe 22\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 23\n",
      "2019-09-05 Stand-up Science 16\n",
      "2019-09-06 RoboCom 23\n",
      "2019-09-19 Bombs Away Cafe 9\n",
      "2019-09-21 Laugh Track Town USA 10\n",
      "2019-10-11 Singu-hilarity 12\n",
      "2019-11-29 Comedy the Musical 10\n",
      "2019-11-29 Crapshoot 10\n",
      "2019-12-06 Silent Background Recording 24\n",
      "2019-04-19 Singu-hilarity 25\n",
      "2019-06-19 Trek Theater 16\n",
      "2019-08-15 Bombs Away Cafe 23\n",
      "2019-08-23 Spectrum 16\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 24\n",
      "2019-09-05 Stand-up Science 17\n",
      "2019-09-06 RoboCom 24\n",
      "2019-09-19 Bombs Away Cafe 10\n",
      "2019-09-21 Laugh Track Town USA 11\n",
      "2019-10-11 Singu-hilarity 13\n",
      "2019-11-29 Comedy the Musical 11\n",
      "2019-11-29 Crapshoot 11\n",
      "2019-12-06 Silent Background Recording 25\n",
      "2019-04-19 Singu-hilarity 26\n",
      "2019-06-19 Trek Theater 17\n",
      "2019-08-15 Bombs Away Cafe 24\n",
      "2019-08-23 Spectrum 17\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 25\n",
      "2019-09-06 RoboCom 25\n",
      "2019-08-15 Bombs Away Cafe 25\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 26\n",
      "2019-09-05 Stand-up Science 18\n",
      "2019-09-06 RoboCom 29\n",
      "2019-09-21 Laugh Track Town USA 16\n",
      "2019-10-11 Singu-hilarity 18\n",
      "2019-11-29 Comedy the Musical 14\n",
      "2019-11-29 Crapshoot 14\n",
      "2019-12-06 Silent Background Recording 30\n",
      "2019-04-18 Bombs Away Cafe 7\n",
      "2019-04-19 Singu-hilarity 28\n",
      "2019-06-19 Trek Theater 18\n",
      "2019-08-15 Bombs Away Cafe 26\n",
      "2019-08-23 Spectrum 18\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 27\n",
      "2019-09-05 Stand-up Science 19\n",
      "2019-09-06 RoboCom 41\n",
      "2019-12-06 Silent Background Recording 43\n",
      "2019-04-19 Singu-hilarity 29\n",
      "2019-05-16 Bombs Away Cafe 5\n",
      "2019-06-19 Trek Theater 19\n",
      "2019-06-20 Bombs Away Cafe 1\n",
      "2019-08-15 Bombs Away Cafe 27\n",
      "2019-08-23 Spectrum 19\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 28\n",
      "2019-09-05 Stand-up Science 20\n",
      "2019-09-06 RoboCom 30\n",
      "2019-09-19 Bombs Away Cafe 13\n",
      "2019-09-21 Laugh Track Town USA 17\n",
      "2019-10-11 Singu-hilarity 19\n",
      "2019-12-06 Silent Background Recording 31\n",
      "2019-04-18 Bombs Away Cafe 12\n",
      "2019-04-19 Singu-hilarity 30\n",
      "2019-05-16 Bombs Away Cafe 6\n",
      "2019-06-19 Trek Theater 20\n",
      "2019-06-20 Bombs Away Cafe 4\n",
      "2019-08-15 Bombs Away Cafe 28\n",
      "2019-08-23 Spectrum 20\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 29\n",
      "2019-09-21 Laugh Track Town USA 18\n",
      "2019-12-06 Silent Background Recording 32\n",
      "2019-04-19 Singu-hilarity 31\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 3\n",
      "2019-09-05 Stand-up Science 2\n",
      "2019-09-06 RoboCom 3\n",
      "2019-09-21 Laugh Track Town USA 3\n",
      "2019-10-11 Singu-hilarity 3\n",
      "2019-11-29 Comedy the Musical 3\n",
      "2019-11-29 Crapshoot 3\n",
      "2019-12-06 Silent Background Recording 3\n",
      "2019-04-19 Singu-hilarity 3\n",
      "2019-05-16 Bombs Away Cafe 2\n",
      "2019-06-19 Trek Theater 2\n",
      "2019-08-15 Bombs Away Cafe 3\n",
      "2019-08-23 Spectrum 2\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 30\n",
      "2019-09-05 Stand-up Science 21\n",
      "2019-09-06 RoboCom 31\n",
      "2019-09-19 Bombs Away Cafe 15\n",
      "2019-09-21 Laugh Track Town USA 19\n",
      "2019-10-11 Singu-hilarity 20\n",
      "2019-11-29 Comedy the Musical 15\n",
      "2019-11-29 Crapshoot 15\n",
      "2019-12-06 Silent Background Recording 33\n",
      "2019-04-19 Singu-hilarity 32\n",
      "2019-05-16 Bombs Away Cafe 7\n",
      "2019-06-19 Trek Theater 21\n",
      "2019-06-20 Bombs Away Cafe 5\n",
      "2019-08-15 Bombs Away Cafe 30\n",
      "2019-08-23 Spectrum 21\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 31\n",
      "2019-09-05 Stand-up Science 22\n",
      "2019-09-06 RoboCom 32\n",
      "2019-12-06 Silent Background Recording 34\n",
      "2019-04-18 Bombs Away Cafe 14\n",
      "2019-04-19 Singu-hilarity 33\n",
      "2019-06-19 Trek Theater 22\n",
      "2019-06-20 Bombs Away Cafe 6\n",
      "2019-08-15 Bombs Away Cafe 31\n",
      "2019-08-23 Spectrum 22\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 32\n",
      "2019-09-06 RoboCom 33\n",
      "2019-04-18 Bombs Away Cafe 15\n",
      "2019-08-15 Bombs Away Cafe 32\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 33\n",
      "2019-09-05 Stand-up Science 23\n",
      "2019-09-06 RoboCom 34\n",
      "2019-09-19 Bombs Away Cafe 16\n",
      "2019-12-06 Silent Background Recording 36\n",
      "2019-04-19 Singu-hilarity 34\n",
      "2019-06-19 Trek Theater 23\n",
      "2019-06-20 Bombs Away Cafe 7\n",
      "2019-08-15 Bombs Away Cafe 33\n",
      "2019-08-23 Spectrum 23\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 34\n",
      "2019-09-05 Stand-up Science 24\n",
      "2019-09-06 RoboCom 52\n",
      "2019-09-21 Laugh Track Town USA 30\n",
      "2019-10-11 Singu-hilarity 30\n",
      "2019-11-29 Comedy the Musical 17\n",
      "2019-11-29 Crapshoot 17\n",
      "2019-12-06 Silent Background Recording 56\n",
      "2019-04-19 Singu-hilarity 35\n",
      "2019-06-19 Trek Theater 24\n",
      "2019-06-20 Bombs Away Cafe 8\n",
      "2019-08-15 Bombs Away Cafe 34\n",
      "2019-08-23 Spectrum 24\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 35\n",
      "2019-09-06 RoboCom 53\n",
      "2019-09-21 Laugh Track Town USA 31\n",
      "2019-10-11 Singu-hilarity 31\n",
      "2019-11-29 Comedy the Musical 18\n",
      "2019-11-29 Crapshoot 18\n",
      "2019-04-19 Singu-hilarity 36\n",
      "2019-08-15 Bombs Away Cafe 35\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 36\n",
      "2019-09-05 Stand-up Science 25\n",
      "2019-09-06 RoboCom 54\n",
      "2019-09-21 Laugh Track Town USA 32\n",
      "2019-10-11 Singu-hilarity 32\n",
      "2019-11-29 Comedy the Musical 19\n",
      "2019-11-29 Crapshoot 19\n",
      "2019-12-06 Silent Background Recording 58\n",
      "2019-06-19 Trek Theater 25\n",
      "2019-06-20 Bombs Away Cafe 9\n",
      "2019-08-15 Bombs Away Cafe 36\n",
      "2019-08-23 Spectrum 25\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 37\n",
      "2019-09-05 Stand-up Science 26\n",
      "2019-09-06 RoboCom 55\n",
      "2019-09-19 Bombs Away Cafe 32\n",
      "2019-09-21 Laugh Track Town USA 33\n",
      "2019-10-11 Singu-hilarity 33\n",
      "2019-11-29 Comedy the Musical 20\n",
      "2019-11-29 Crapshoot 20\n",
      "2019-12-06 Silent Background Recording 59\n",
      "2019-04-18 Bombs Away Cafe 20\n",
      "2019-04-19 Singu-hilarity 41\n",
      "2019-04-22 Class Performance 20\n",
      "2019-05-16 Bombs Away Cafe 8\n",
      "2019-06-19 Trek Theater 31\n",
      "2019-06-20 Bombs Away Cafe 13\n",
      "2019-08-15 Bombs Away Cafe 37\n",
      "2019-08-23 Spectrum 31\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 4\n",
      "2019-09-05 Stand-up Science 3\n",
      "2019-09-06 RoboCom 6\n",
      "2019-12-06 Silent Background Recording 6\n",
      "2019-04-18 Bombs Away Cafe 1\n",
      "2019-04-19 Singu-hilarity 4\n",
      "2019-04-22 Class Performance 3\n",
      "2019-06-19 Trek Theater 3\n",
      "2019-08-15 Bombs Away Cafe 4\n",
      "2019-08-23 Spectrum 3\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 5\n",
      "2019-09-05 Stand-up Science 4\n",
      "2019-09-06 RoboCom 7\n",
      "2019-12-06 Silent Background Recording 7\n",
      "2019-04-18 Bombs Away Cafe 2\n",
      "2019-04-19 Singu-hilarity 5\n",
      "2019-04-22 Class Performance 4\n",
      "2019-06-19 Trek Theater 4\n",
      "2019-08-15 Bombs Away Cafe 5\n",
      "2019-08-23 Spectrum 4\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 6\n",
      "2019-09-05 Stand-up Science 5\n",
      "2019-09-06 RoboCom 8\n",
      "2019-12-06 Silent Background Recording 8\n",
      "2019-04-19 Singu-hilarity 6\n",
      "2019-06-19 Trek Theater 5\n",
      "2019-08-15 Bombs Away Cafe 6\n",
      "2019-08-23 Spectrum 5\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 7\n",
      "2019-09-06 RoboCom 9\n",
      "2019-12-06 Silent Background Recording 9\n",
      "2019-04-19 Singu-hilarity 7\n",
      "2019-08-15 Bombs Away Cafe 7\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 8\n",
      "2019-09-05 Stand-up Science 6\n",
      "2019-09-06 RoboCom 10\n",
      "2019-12-06 Silent Background Recording 10\n",
      "2019-04-19 Singu-hilarity 8\n",
      "2019-06-19 Trek Theater 6\n",
      "2019-08-15 Bombs Away Cafe 8\n",
      "2019-08-23 Spectrum 6\n",
      "2019-04-13 Cienna Nerdy Show at The Drake 9\n",
      "2019-09-05 Stand-up Science 7\n",
      "2019-09-06 RoboCom 11\n",
      "2019-12-06 Silent Background Recording 11\n",
      "2019-04-19 Singu-hilarity 9\n",
      "2019-04-22 Class Performance 5\n",
      "2019-05-16 Bombs Away Cafe 3\n",
      "2019-06-19 Trek Theater 7\n",
      "2019-08-15 Bombs Away Cafe 9\n",
      "2019-08-23 Spectrum 7\n",
      "2019-09-06 RoboCom 15\n",
      "2019-09-19 Bombs Away Cafe 5\n",
      "2019-09-21 Laugh Track Town USA 7\n",
      "2019-10-11 Singu-hilarity 8\n",
      "2019-11-29 Comedy the Musical 6\n",
      "2019-11-29 Crapshoot 6\n",
      "2019-12-06 Silent Background Recording 14\n",
      "2019-09-06 RoboCom 26\n",
      "2019-09-19 Bombs Away Cafe 12\n",
      "2019-09-21 Laugh Track Town USA 13\n",
      "2019-10-11 Singu-hilarity 15\n",
      "2019-11-29 Comedy the Musical 13\n",
      "2019-11-29 Crapshoot 13\n",
      "2019-12-06 Silent Background Recording 27\n",
      "2019-09-06 RoboCom 28\n",
      "2019-09-21 Laugh Track Town USA 15\n",
      "2019-10-11 Singu-hilarity 17\n",
      "2019-12-06 Silent Background Recording 29\n",
      "2019-04-22 Class Performance 19\n",
      "2019-09-06 RoboCom 35\n",
      "2019-09-19 Bombs Away Cafe 17\n",
      "2019-09-21 Laugh Track Town USA 20\n",
      "2019-10-11 Singu-hilarity 21\n",
      "2019-12-06 Silent Background Recording 37\n",
      "2019-09-06 RoboCom 36\n",
      "2019-09-19 Bombs Away Cafe 18\n",
      "2019-09-21 Laugh Track Town USA 21\n",
      "2019-10-11 Singu-hilarity 22\n",
      "2019-12-06 Silent Background Recording 38\n",
      "2019-09-06 RoboCom 37\n",
      "2019-09-19 Bombs Away Cafe 19\n",
      "2019-09-21 Laugh Track Town USA 22\n",
      "2019-10-11 Singu-hilarity 23\n",
      "2019-12-06 Silent Background Recording 39\n",
      "2019-09-06 RoboCom 38\n",
      "2019-12-06 Silent Background Recording 40\n",
      "2019-04-18 Bombs Away Cafe 5\n",
      "2019-04-19 Singu-hilarity 11\n",
      "2019-04-22 Class Performance 7\n",
      "2019-06-19 Trek Theater 26\n",
      "2019-06-20 Bombs Away Cafe 2\n",
      "2019-08-23 Spectrum 26\n",
      "2019-09-06 RoboCom 39\n",
      "2019-12-06 Silent Background Recording 41\n",
      "2019-04-18 Bombs Away Cafe 6\n",
      "2019-04-19 Singu-hilarity 12\n",
      "2019-04-22 Class Performance 8\n",
      "2019-06-19 Trek Theater 27\n",
      "2019-06-20 Bombs Away Cafe 3\n",
      "2019-08-23 Spectrum 27\n",
      "2019-09-06 RoboCom 4\n",
      "2019-09-19 Bombs Away Cafe 1\n",
      "2019-09-21 Laugh Track Town USA 4\n",
      "2019-10-11 Singu-hilarity 4\n",
      "2019-12-06 Silent Background Recording 4\n",
      "2019-09-06 RoboCom 40\n",
      "2019-09-19 Bombs Away Cafe 20\n",
      "2019-09-21 Laugh Track Town USA 23\n",
      "2019-10-11 Singu-hilarity 24\n",
      "2019-11-29 Comedy the Musical 16\n",
      "2019-11-29 Crapshoot 16\n",
      "2019-12-06 Silent Background Recording 42\n",
      "2019-09-06 RoboCom 42\n",
      "2019-09-19 Bombs Away Cafe 21\n",
      "2019-09-21 Laugh Track Town USA 24\n",
      "2019-10-11 Singu-hilarity 25\n",
      "2019-12-06 Silent Background Recording 44\n",
      "2019-09-06 RoboCom 43\n",
      "2019-09-19 Bombs Away Cafe 22\n",
      "2019-09-21 Laugh Track Town USA 25\n",
      "2019-10-11 Singu-hilarity 26\n",
      "2019-12-06 Silent Background Recording 45\n",
      "2019-09-06 RoboCom 44\n",
      "2019-09-19 Bombs Away Cafe 23\n",
      "2019-09-21 Laugh Track Town USA 26\n",
      "2019-10-11 Singu-hilarity 27\n",
      "2019-12-06 Silent Background Recording 46\n",
      "2019-09-06 RoboCom 45\n",
      "2019-09-19 Bombs Away Cafe 24\n",
      "2019-10-11 Singu-hilarity 28\n",
      "2019-09-06 RoboCom 46\n",
      "2019-09-19 Bombs Away Cafe 25\n",
      "2019-09-21 Laugh Track Town USA 28\n",
      "2019-10-11 Singu-hilarity 29\n",
      "2019-12-06 Silent Background Recording 48\n",
      "2019-09-06 RoboCom 47\n",
      "2019-09-19 Bombs Away Cafe 27\n",
      "2019-12-06 Silent Background Recording 50\n",
      "2019-04-18 Bombs Away Cafe 16\n",
      "2019-04-19 Singu-hilarity 37\n",
      "2019-06-19 Trek Theater 28\n",
      "2019-06-20 Bombs Away Cafe 10\n",
      "2019-08-23 Spectrum 28\n",
      "2019-09-06 RoboCom 48\n",
      "2019-12-06 Silent Background Recording 51\n",
      "2019-04-19 Singu-hilarity 38\n",
      "2019-09-06 RoboCom 49\n",
      "2019-09-19 Bombs Away Cafe 28\n",
      "2019-12-06 Silent Background Recording 52\n",
      "2019-04-18 Bombs Away Cafe 18\n",
      "2019-04-19 Singu-hilarity 39\n",
      "2019-06-19 Trek Theater 29\n",
      "2019-06-20 Bombs Away Cafe 11\n",
      "2019-08-23 Spectrum 29\n",
      "2019-09-06 RoboCom 5\n",
      "2019-09-19 Bombs Away Cafe 2\n",
      "2019-09-21 Laugh Track Town USA 5\n",
      "2019-10-11 Singu-hilarity 5\n",
      "2019-09-06 RoboCom 50\n",
      "2019-09-19 Bombs Away Cafe 29\n",
      "2019-12-06 Silent Background Recording 53\n",
      "2019-04-18 Bombs Away Cafe 19\n",
      "2019-04-19 Singu-hilarity 40\n",
      "2019-06-19 Trek Theater 30\n",
      "2019-06-20 Bombs Away Cafe 12\n",
      "2019-08-23 Spectrum 30\n",
      "2019-09-06 RoboCom 51\n",
      "2019-09-19 Bombs Away Cafe 30\n",
      "2019-12-06 Silent Background Recording 54\n",
      "2019-09-19 Bombs Away Cafe 11\n",
      "2019-09-21 Laugh Track Town USA 12\n",
      "2019-12-06 Silent Background Recording 26\n",
      "2019-04-19 Singu-hilarity 27\n",
      "2019-09-19 Bombs Away Cafe 14\n",
      "2019-04-18 Bombs Away Cafe 13\n",
      "2019-08-15 Bombs Away Cafe 29\n",
      "2019-09-19 Bombs Away Cafe 26\n",
      "2019-09-21 Laugh Track Town USA 29\n",
      "2019-09-19 Bombs Away Cafe 31\n",
      "2019-09-19 Bombs Away Cafe 6\n",
      "2019-10-11 Singu-hilarity 9\n",
      "2019-11-29 Comedy the Musical 7\n",
      "2019-11-29 Crapshoot 7\n",
      "2019-09-19 Bombs Away Cafe 8\n",
      "2019-09-21 Laugh Track Town USA 9\n",
      "2019-10-11 Singu-hilarity 11\n",
      "2019-11-29 Comedy the Musical 9\n",
      "2019-11-29 Crapshoot 9\n",
      "2019-12-06 Silent Background Recording 17\n",
      "2019-04-19 Singu-hilarity 16\n",
      "2019-04-22 Class Performance 12\n",
      "2019-08-15 Bombs Away Cafe 14\n",
      "2019-09-21 Laugh Track Town USA 27\n",
      "2019-12-06 Silent Background Recording 47\n",
      "2019-10-11 Singu-hilarity 14\n",
      "2019-11-29 Comedy the Musical 12\n",
      "2019-11-29 Crapshoot 12\n",
      "2019-12-06 Silent Background Recording 12\n",
      "2019-04-19 Singu-hilarity 10\n",
      "2019-04-22 Class Performance 6\n",
      "2019-12-06 Silent Background Recording 15\n",
      "2019-12-06 Silent Background Recording 2\n",
      "2019-12-06 Silent Background Recording 35\n",
      "2019-12-06 Silent Background Recording 49\n",
      "2019-12-06 Silent Background Recording 5\n",
      "2019-12-06 Silent Background Recording 55\n",
      "2019-12-06 Silent Background Recording 57\n",
      "2019-04-18 Bombs Away Cafe 17\n",
      "2019-04-18 Bombs Away Cafe 8\n",
      "2019-04-18 Bombs Away Cafe 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from scipy.stats import pearsonr\n",
    "def overallCorrelation(combine_joke_dict):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    d=[]\n",
    "    e=[]\n",
    "    f=[]\n",
    "    g=[]\n",
    "    h=[]\n",
    "    for i in combine_joke_dict:\n",
    "        arr=combine_joke_dict[i]\n",
    "        for joke in arr:\n",
    "            x.append(joke.intensity)\n",
    "            y.append(joke.pitch)\n",
    "            z.append(joke.stinten)\n",
    "            d.append(joke.stpit)\n",
    "            e.append(joke.max_inten)\n",
    "            f.append(joke.min_inten)\n",
    "            g.append(joke.max_pitch)\n",
    "            h.append(joke.min_pitch)\n",
    "    \n",
    "    arr=[x,y,z,d,e,f,g,h]\n",
    "    result={}\n",
    "    var=['intensity','pitch','stdIntensity','stdPitch','maxIntensity','minIntensity','maxPitch','minPitch']\n",
    "    length=len(var)\n",
    "    \n",
    "    pontential=\"The correlation coefficient are higher than 7:\\n\"\n",
    "    \n",
    "    for i in range(0,length-1):\n",
    "        for j in range(i+1,length):\n",
    "            #save txt result\n",
    "            key=var[i]+'-'+var[j]\n",
    "            result[key]=pearsonr(arr[i],arr[j])[0]\n",
    "            if(abs(result[key])>0.7):\n",
    "                pontential=pontential+key+\": \"+str(result[key])+\"\\n\"\n",
    "            \n",
    "            #draw plot\n",
    "            path=\"../jokeoutput/overall-correlation/\"+key+\".png\"            \n",
    "            draw2Dplot(var[i],var[j],arr[i],arr[j],path)\n",
    "\n",
    "    print(len(result))\n",
    "    txtName=\"../jokeoutput/overall-correlation/correlation.txt\"\n",
    "    \n",
    "    output=''\n",
    "    for n in result:\n",
    "        output=output+n+\": \"+str(result[n])+\"\\n\"\n",
    "\n",
    "    output=output+\"\\n\\n\"+pontential\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(output)\n",
    "    f.close()\n",
    "    \n",
    "def jokeWiseCorrelation(combine_joke_dict):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    d=[]\n",
    "    e=[]\n",
    "    f=[]\n",
    "    g=[]\n",
    "    h=[]\n",
    "    var=['intensity','pitch','stdIntensity','stdPitch','maxIntensity','minIntensity','maxPitch','minPitch']\n",
    "    length=len(var)\n",
    "    pontential=\"The correlation coefficient are higher than 7:\\n\"\n",
    "    \n",
    "    for i in combine_joke_dict:\n",
    "        arr=combine_joke_dict[i]\n",
    "        x.clear()\n",
    "        y.clear()\n",
    "        z.clear()\n",
    "        d.clear()\n",
    "        e.clear()\n",
    "        f.clear()\n",
    "        g.clear()\n",
    "        h.clear()\n",
    "        jokename=''\n",
    "        for joke in arr:\n",
    "            x.append(joke.intensity)\n",
    "            y.append(joke.pitch)\n",
    "            z.append(joke.stinten)\n",
    "            d.append(joke.stpit)\n",
    "            e.append(joke.max_inten)\n",
    "            f.append(joke.min_inten)\n",
    "            g.append(joke.max_pitch)\n",
    "            h.append(joke.min_pitch) \n",
    "            jokename=joke.jokeName\n",
    "            \n",
    "        jokename=jokename.replace('/','-')\n",
    "        arr=[x,y,z,d,e,f,g,h]\n",
    "        result={}\n",
    "        dirPath=\"../jokeoutput/jokewise-correlation/\"+jokename\n",
    "\n",
    "        if not os.path.exists(dirPath):\n",
    "            os.mkdir(dirPath)\n",
    "                \n",
    "        for i in range(0,length-1):\n",
    "            for j in range(i+1,length):\n",
    "                #save txt result\n",
    "                key=var[i]+'-'+var[j]\n",
    "#                 print(len(arr[i]),len(arr[j]))\n",
    "                if(len(arr[i])<2):\n",
    "                    result[key]=\"Data set is smaller than 2\"\n",
    "                    \n",
    "                    \n",
    "                else:    \n",
    "                    result[key]=pearsonr(arr[i],arr[j])[0]\n",
    "                    if(abs(result[key])>0.7):\n",
    "                        pontential=pontential+key+\": \"+str(result[key])+\"\\n\"\n",
    "                    #draw plot\n",
    "                    path=dirPath+\"/\"+key+\".png\"           \n",
    "                    print(path)\n",
    "                    draw2Dplot(var[i],var[j],arr[i],arr[j],path)\n",
    "\n",
    "        txtName=dirPath+\"/correlation.txt\"\n",
    "\n",
    "        output=''\n",
    "        for n in result:\n",
    "            output=output+n+\": \"+str(result[n])+\"\\n\"\n",
    "\n",
    "        output=output+\"\\n\\n\"+pontential\n",
    "        if os.path.isfile(txtName):\n",
    "            os.remove(txtName) \n",
    "        file = open(txtName, \"a\")\n",
    "        file.write(output)\n",
    "        file.close()\n",
    "        pontential=\"The correlation coefficient are higher than 7:\\n\"\n",
    "    \n",
    "def draw2Dplot(Xname,Yname,x,y,path):\n",
    "    fig=plt.figure(figsize=(10,6))\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(Xname+\"-\"+Yname)\n",
    "    plt.xlabel(Xname)\n",
    "    plt.ylabel(Yname)\n",
    "    pngName=path\n",
    "    #remove the existing png file\n",
    "    if os.path.isfile(pngName):\n",
    "        os.remove(pngName) \n",
    "    #save as png file\n",
    "    plt.savefig(pngName)\n",
    "#     plt.show()\n",
    "    plt.close(fig) \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    global jokeNameDict\n",
    "    jokeNameDict=getJokeNameForEachPerformance(r\"E:\\CapstoneWork\\k-means-test_by_Tony\\joke_name_matching\")\n",
    "    #i am using directory pitch_inten_avg_std_minmax since it is the test contain most information\n",
    "    combine_joke_dict=findAlltxtAndCombine(r\"E:\\CapstoneWork\\k-means-test_by_Tony\\jokeinput\")\n",
    "    for x in combine_joke_dict:\n",
    "        for joke in combine_joke_dict[x]:\n",
    "            print(joke.performance,joke.id)\n",
    "    #print(len(combine_joke_dict))\n",
    "#     for x in combine_joke_dict:\n",
    "#         clusterDataIn2D(combine_joke_dict[x],1)\n",
    "#     for x in combine_joke_dict:\n",
    "#         clusterDataIn4D(combine_joke_dict[x])\n",
    "    for x in combine_joke_dict:\n",
    "        clusterDataIn8D(combine_joke_dict[x])\n",
    "#     overallCorrelation(combine_joke_dict)\n",
    "#     jokeWiseCorrelation(combine_joke_dict)\n",
    "        \n",
    "main()\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
