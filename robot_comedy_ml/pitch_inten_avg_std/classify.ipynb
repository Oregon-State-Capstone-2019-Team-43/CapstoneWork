{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68873216955480865"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#made by: Ella Bisbee eloise.bisbee@tufts.edu 8/20/19\n",
    "#this program will classify the data in clean_comedy_data.csv in ways specified\n",
    "#by the user in the code below.\n",
    "\n",
    "#The program expects that clean_comedy_data.csv is in the same directory, and has\n",
    "#columns: PerformanceId, JokeId, Pitch, PitchStd, Intensity, IntensityStd,\n",
    "#HumanScore, HumanScorePostJokeOnly\n",
    "\n",
    "#The actual function that does the classification and validation is classifyAndVal,\n",
    "#which takes options specified in the comment above the function.\n",
    "#The options for classification are knn, svm, or decision tree.\n",
    "#The options for validation are random split, nfold, or leave one performance out.\n",
    "\n",
    "#As written now, the classifyAndVal function takes the data and options and returns\n",
    "#The percent of test data classified correctly. Hopefully the code is well commented\n",
    "#enough that you know where to change anything if you wish to adapt the program (email\n",
    "#me if not!)\n",
    "\n",
    "#There is also the option to normalize or not normalize the data, either normalizing \n",
    "#both the pitch and intensity or just intensity. The method of normalization is to normalize\n",
    "#every value against the gdpr joke (jokeId 4) for it's performance.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "#used to determine if a string is an int\n",
    "def isInt(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "#takes: com_data (the np.array'ed comedy data from the file),\n",
    "#X (an np array containing pitch, pitchstd, intensity, intensitystd arrays\n",
    "#for each joke), \n",
    "#y (the ground truth -1, 0, or 1 ratings of each joke in X),\n",
    "#val_option: either 'rand', 'nfold', or 'leave1out' indicating how\n",
    "#the classifier should be validated.\n",
    "#class_option: either 'knn', 'svm', or 'dt' for the classification\n",
    "#technique to be used. \n",
    "#returns the percent of test data correctly classified in decimal form.\n",
    "def classifyAndVal(com_data, X, y, val_option, class_option):\n",
    "    if val_option == 'rand':\n",
    "        train, test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state=1, stratify=y)\n",
    "        if class_option == 'knn':\n",
    "            #adjust neighbs value if you wish for a different number of neighbors\n",
    "            neighbs = 5\n",
    "            #weight can either be 'uniform' or 'distance', as per scikit learn knn\n",
    "            weight = 'uniform'\n",
    "            clf = neighbors.KNeighborsClassifier(neighbs, weights=weight)\n",
    "        elif class_option == 'svm':\n",
    "            clf = svm.SVC()\n",
    "        elif class_option == 'dt':\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "        else: \n",
    "            print('invalid classification option. Options are: knn, svm, dt.')\n",
    "            return\n",
    "        clf.fit(train, y_train)\n",
    "        return clf.score(test, y_test)\n",
    "    elif val_option == 'nfold':\n",
    "        #adjust if you want a different number of folds for nfolds\n",
    "        n_folds = 5\n",
    "        if class_option == 'knn':\n",
    "            #adjust neighbs value if you wish for a different number of neighbors\n",
    "            neighbs = 5\n",
    "            #weight can either be 'uniform' or 'distance', as per scikit learn knn\n",
    "            weight = 'uniform'\n",
    "            clf = neighbors.KNeighborsClassifier(neighbs, weights=weight)\n",
    "        elif class_option == 'svm':\n",
    "            clf = svm.SVC()\n",
    "        elif class_option == 'dt':\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "        else: \n",
    "            print('invalid classification option. Options are: knn, svm, dt.')\n",
    "            return\n",
    "        #cv_scores contains the scores for all n fold cross validations.\n",
    "        cv_scores = cross_val_score(clf, X, y, cv=n_folds)\n",
    "        return np.mean(cv_scores)\n",
    "    elif val_option == 'leave1out':\n",
    "        #this block counts the number of performances included in the data,\n",
    "        #and what indices in X they start and end at\n",
    "        pers = {}\n",
    "        curr = -1.0\n",
    "        for i in range(0, len(com_data)):\n",
    "            if curr != com_data[i][0]:\n",
    "                if curr != -1:\n",
    "                    pers[curr].append(i - 1)\n",
    "                curr = com_data[i][0]\n",
    "                pers[curr] = [i]\n",
    "        pers[curr].append(len(com_data) - 1)\n",
    "        #this block iterates through each performance and puts that performance in \n",
    "        #the test and y_test arrays, and every other performance in the train and y_train\n",
    "        #The scores for each performance being used as the test is placed in \n",
    "        #scores dictionary.\n",
    "        scores = {}\n",
    "        for elem in pers:\n",
    "            if len(X[:pers[elem][0], :]) == 0:\n",
    "                train = X[pers[elem][1] + 1:, :]\n",
    "                y_train = y[pers[elem][1] + 1:]\n",
    "            elif len(X[pers[elem][1] + 1:, :]) == 0:\n",
    "                train = X[:pers[elem][0], :]\n",
    "                y_train = y[:pers[elem][0]]\n",
    "            else:\n",
    "                train = np.concatenate((X[:int(pers[elem][0]), :], X[int(pers[elem][1]) + 1:, :]), axis=0)\n",
    "                y_train = np.concatenate((y[:int(pers[elem][0])], y[int(pers[elem][1]) + 1:]), axis=0)\n",
    "            test = X[pers[elem][0]:pers[elem][1]+1, :]\n",
    "            y_test = y[pers[elem][0]:pers[elem][1]+1]\n",
    "            if class_option == 'knn':\n",
    "                #adjust neighbs value if you wish for a different number of neighbors\n",
    "                neighbs = 5\n",
    "                #weight can either be 'uniform' or 'distance', as per scikit learn knn\n",
    "                weight = 'uniform'\n",
    "                clf = neighbors.KNeighborsClassifier(neighbs, weights=weight)\n",
    "            elif class_option == 'svm':\n",
    "                clf = svm.SVC()\n",
    "            elif class_option == 'dt':\n",
    "                clf = tree.DecisionTreeClassifier()\n",
    "            else:\n",
    "                print('invalid classification option. Options are: knn, svm, dt.')\n",
    "                return\n",
    "            clf.fit(train, y_train)\n",
    "            scores[elem] = clf.score(test, y_test)\n",
    "        #calculates the average score and returns it\n",
    "        sum_score = 0\n",
    "        for i in scores:\n",
    "            sum_score += scores[i]\n",
    "        return sum_score / len(scores)\n",
    "    else:\n",
    "        print(\"invalid validation option. Options are: rand, nfold, leave1out\")\n",
    "        return\n",
    "    \n",
    "#this function takes a value and a gdpr joke value and returns\n",
    "#a normalized value. If the gdpr value is 0, it defaults to 200\n",
    "def normalize(val, gdpr):\n",
    "    default = 200\n",
    "    if gdpr == 0:\n",
    "        return val/default\n",
    "    else:\n",
    "        return val/gdpr\n",
    "\n",
    "#this function gets a specific gdpr value from the dict. of \n",
    "#gdpr values corresponding to the 'key' performance. It get's\n",
    "#the j'th value. If the key is not a valid key in the dict., it \n",
    "#returns an estimated average based on what j is (corresponding\n",
    "#to the order of pitch, pitchstd, intensity, intensitystd in the data)\n",
    "def getGdpr(gdpr_list, key, j):\n",
    "    try:\n",
    "        gdpr_list[key]\n",
    "        return gdpr_list[key][j]\n",
    "    except KeyError:\n",
    "        if j == 0:\n",
    "            return 200\n",
    "        elif j == 1:\n",
    "            return 30\n",
    "        elif j == 2:\n",
    "            return 80\n",
    "        elif j == 3:\n",
    "            return 5\n",
    "        else:\n",
    "            return 50\n",
    "\n",
    "#This function iterates through the X 2d list (which is expected to\n",
    "#be the raw_com_data array) and normalizes the pitch, pitchstd, intensity\n",
    "# and intensitystd values,then returns the normalized array\n",
    "def normalizeAll(X, gdpr_vals):\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0,4):\n",
    "            raw_com_data[i][2 + j] = normalize(raw_com_data[i][2 + j], \n",
    "                                               getGdpr(gdpr_vals, raw_com_data[i][0],j))\n",
    "    return X\n",
    "\n",
    "#This function iterates through the X 2d list (which is expected to\n",
    "#be the raw_com_data array) and normalizes the intensity and intensitystd\n",
    "#values, then returns the normalized array\n",
    "def normalizeIntensity(X, gdpr_vals):\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(2,4):\n",
    "            raw_com_data[i][2 + j] = normalize(raw_com_data[i][2 + j], \n",
    "                                               getGdpr(gdpr_vals, raw_com_data[i][0],j))\n",
    "    return X\n",
    "\n",
    "#_________________________________________________________________________________________________________________________\n",
    "#______________________________________MAIN FUNCTION BODY BEGINS HERE_____________________________________________________\n",
    "#_________________________________________________________________________________________________________________________\n",
    "\n",
    "#read in csv file\n",
    "raw_com_data = []\n",
    "com_data_cols = []\n",
    "gdpr_vals = {}\n",
    "with open('clean_comedy_data.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    count = 0\n",
    "    curr_per = -1\n",
    "    for row in csv_reader:\n",
    "        if count == 0:\n",
    "            com_data_cols = row\n",
    "        else:\n",
    "            #this little if statement block is to add the gdpr joke to\n",
    "            #the list of gdpr values. The key is the performanceId\n",
    "            if curr_per != int(row[0]) and int(row[1]) == 4:\n",
    "                cur_per = int(row[0])\n",
    "                gdpr_vals[int(row[0])] = [float(row[2]), float(row[3]), float(row[4]), float(row[5])] \n",
    "            for i in range(0, len(row)):\n",
    "                if isInt(row[i]):\n",
    "                    row[i] = int(row[i])\n",
    "                else:\n",
    "                    row[i] = float(row[i])\n",
    "            raw_com_data.append(row)\n",
    "        count += 1\n",
    "\n",
    "#uncomment if you want to normalize all data:\n",
    "raw_com_data = normalizeAll(raw_com_data, gdpr_vals)\n",
    "\n",
    "#uncomment if you want to normalize intensity:\n",
    "#raw_com_data = normalizeIntensity(raw_com_data, gdpr_vals)\n",
    "\n",
    "#extracts just the pitch and intensity values into X, and \n",
    "#human rating after joke only into y\n",
    "\n",
    "com_data = np.array(raw_com_data)\n",
    "X = com_data[:, 2:6]\n",
    "y = com_data[:, 7:]\n",
    "y = y.ravel()\n",
    "\n",
    "\n",
    "#this is the call to classifyAndVal, where the actual brute of \n",
    "#computation is carried out. Look at comment above function definition\n",
    "#for information about options\n",
    "classifyAndVal(com_data, X, y, 'leave1out', 'svm')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
