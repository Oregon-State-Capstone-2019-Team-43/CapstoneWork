{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class store the internsity and pitch \n",
    "import pandas as pd\n",
    "class Pause_Info:\n",
    "  def __init__(self,intensity,stinten,pitch,stpit,max_inten,min_inten,max_pitch,min_pitch,performance,id,jokeName):\n",
    "    self.intensity = intensity\n",
    "    self.stinten= stinten\n",
    "    self.pitch = pitch\n",
    "    self.stpit= stpit\n",
    "    self.max_inten=max_inten\n",
    "    self.min_inten=min_inten\n",
    "    self.max_pitch=max_pitch\n",
    "    self.min_pitch=min_pitch\n",
    "    self.performance=performance\n",
    "    self.id=id\n",
    "    self.jokeName=jokeName\n",
    "    self.midjoke=-100\n",
    "    self.intensityRange=max_inten-min_inten\n",
    "    self.pitchRange=max_pitch-min_pitch\n",
    "    self.predictY=-1\n",
    "    \n",
    "#this function loop through the folder \"joke_name_matching\" and make a dictionary of \n",
    "#joke id and joke name for each performance\n",
    "def getJokeNameForEachPerformance(folderPath):\n",
    "    os.chdir(folderPath)\n",
    "    \n",
    "    jokeNameDict={}\n",
    "    \n",
    "    for file in glob.glob(\"*.txt\"):\n",
    "        idDict={}\n",
    "        filepath=folderPath+'\\\\'+file\n",
    "        f = open(filepath, \"r\")\n",
    "        key=f.readline()\n",
    "        key=key.replace(\"\\x00\",\"\")\n",
    "        key=key.replace(\"\\n\",\"\")\n",
    "#         print(key)\n",
    "        content=f.read();\n",
    "        f.close()\n",
    "        content=content.replace(\"\\x00\",\"\")\n",
    "        content=content.replace(\"\\n\\n\",\"\\n\")\n",
    "        if not content:\n",
    "            continue\n",
    "        lines=content.split('\\n')\n",
    "        lines.pop(0)\n",
    "        lines.pop(-1)\n",
    "        for line in lines:\n",
    "            jokename=line.split(':')[0]\n",
    "            id=int(line.split(':')[1].split('.')[0].split('_')[1])\n",
    "#             print(jokename,id)\n",
    "            idDict[id]=jokename\n",
    "        jokeNameDict[key]=idDict\n",
    "    return jokeNameDict\n",
    "            \n",
    "\n",
    "#This function extract intensity and pitch info from txt file and put all info in to a dictionary\n",
    "def readTxT(path):\n",
    "    f = open(path, \"r\")\n",
    "    line = f.readline()\n",
    "    \n",
    "    #store the joke title\n",
    "    Title = line.split('\\\\')[-2]\n",
    "    Title=Title.replace(\"\\x00\",\"\")\n",
    "    joke_dict = {}\n",
    "\n",
    "    content=f.read();\n",
    "    f.close()\n",
    "    \n",
    "    #replace all these werid \\x00 in python\n",
    "    #also replace all the extra newline char\n",
    "    content=content.replace(\"\\x00\",\"\")\n",
    "    content=content.replace(\"\\n\\n\",\"\\n\")\n",
    "    lines=content.split('\\n')\n",
    "    \n",
    "    #remove the first and last extra new line char\n",
    "    lines.pop(0)\n",
    "    lines.pop(-1)\n",
    "\n",
    "    count,intensity,stinten,pitch,stpit,max_inten,min_inten,max_pitch,min_pitch=0,0,0,0,0,0,0,0,0\n",
    "    digits=2\n",
    "    \n",
    "    #store 7 info of each audio\n",
    "    for line in lines:\n",
    "        if(count%9==0):\n",
    "            name=line.split('.')[0]\n",
    "            name=name.split('_')[-1]\n",
    "            id=int(name)\n",
    "        elif(count%9==1):\n",
    "            intensity=round(float(line),digits)\n",
    "        elif(count%9==2):\n",
    "            stinten=round(float(line),digits)\n",
    "        elif(count%9==3):\n",
    "            min_inten=round(float(line),digits)\n",
    "        elif(count%9==4):\n",
    "            max_inten=round(float(line),digits)\n",
    "        elif(count%9==5):\n",
    "            pitch=round(float(line),digits)\n",
    "        elif(count%9==6):\n",
    "            stpit=round(float(line),digits)   \n",
    "        elif(count%9==7):\n",
    "            max_pitch=round(float(line),digits)\n",
    "        else:\n",
    "            min_pitch=round(float(line),digits)\n",
    "            if(Title not in jokeNameDict):\n",
    "                break\n",
    "            idDict=jokeNameDict[Title]\n",
    "            jokeName=idDict[id]\n",
    "            #print(jokeName)\n",
    "            joke_dict[jokeName]=Pause_Info(intensity,stinten,pitch,stpit,max_inten,min_inten,max_pitch,min_pitch,Title,id,jokeName)\n",
    "            if(Title not in perNameDict):\n",
    "                perNameDict[Title]=1;\n",
    "                \n",
    "            key=Title+\"-\"+str(id)\n",
    "            joke_dict[jokeName].midjoke=humanRateDict[key]\n",
    "        # print(Title,id)\n",
    "        count+=1\n",
    "    return joke_dict\n",
    "\n",
    "\n",
    "import glob, os\n",
    "\n",
    "\n",
    "\n",
    "#in combine_joke_dict,\n",
    "#key of combine_joke_dict represent the joke id\n",
    "#value of combine_joke_dict is an array of 'Pause_Info' who are the same joke but in different perofrmance\n",
    "#len of value represent how many different perofrmance contain this joke \n",
    "def findAlltxtAndCombine(folderPath):\n",
    "    os.chdir(folderPath)\n",
    "    combine_joke_dict={}\n",
    "    \n",
    "    #find all txt file inside folder\n",
    "    for file in glob.glob(\"*.txt\"):\n",
    "        filepath=folderPath+'\\\\'+file\n",
    "        single_joke_dict=readTxT(filepath)   \n",
    "        for x in single_joke_dict:\n",
    "            y=single_joke_dict[x]\n",
    "            if x in combine_joke_dict:\n",
    "                combine_joke_dict[x].append(y)\n",
    "            else:\n",
    "                combine_joke_dict[x]=[y]\n",
    "    return combine_joke_dict         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import scale\n",
    "from numpy import random, float\n",
    "# plt.rcParams['font.sans-serif']=['SimHei']\n",
    "# plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "#info_arr represent an array of same joke in different performances\n",
    "#choice=1 is using intensity and pitch as x-y axis\n",
    "#choice=2 is using std intensity and std pitch as x-y axis\n",
    "def clusterDataIn2D(Info_arr,choice):\n",
    "    jokeid=Info_arr[0].jokeName.replace('/','-')\n",
    "    data=[]\n",
    "    x=[]\n",
    "    y=[]\n",
    "    performanceName=[]\n",
    "    Xname,Yname='',''\n",
    "    if(choice==1):\n",
    "        for joke in Info_arr:\n",
    "            X=joke.intensity\n",
    "            Y=joke.pitch\n",
    "            data.append((X,Y))\n",
    "            performanceName.append(joke.performance)\n",
    "            x.append(X)\n",
    "            y.append(Y)\n",
    "            Xname=\"intensity\"\n",
    "            Yname=\"pitch\"\n",
    "    elif(choice==2):\n",
    "        for joke in Info_arr:\n",
    "            X=joke.stinten\n",
    "            Y=joke.stpit\n",
    "            data.append((X,Y))\n",
    "            performanceName.append(joke.performance)\n",
    "            x.append(X)\n",
    "            y.append(Y)\n",
    "            Xname=\"standard deviation intensity\"\n",
    "            Yname=\"standard deviation pitch\"\n",
    "    \n",
    "    #if the data set is smller than 2,we will ignore it.\n",
    "    if(len(data)<2):\n",
    "        return \n",
    "        \n",
    "    # spilt them into 2 group\n",
    "        \n",
    "    model = KMeans(n_clusters=2)\n",
    "\n",
    "    # Note I'm scaling the data to normalize it! Important for good results.\n",
    "    model = model.fit(scale(data))\n",
    "\n",
    "    # We can look at the clusters each data point was assigned to\n",
    "\n",
    "    \n",
    "    count=0\n",
    "    Group0=[]\n",
    "    Group1=[]\n",
    "    for i in data:\n",
    "        #print(\"performance Name: \"+str(performanceName[count])+\"\\t\",\"Data values: \"+str(i)+\"\\t\",\"Group ID: \"+str(model.labels_[count]))  \n",
    "        if(model.labels_[count]==0):\n",
    "            Group0.append((performanceName[count],str(i)))\n",
    "        else:\n",
    "            Group1.append((performanceName[count],str(i)))\n",
    "        count+=1\n",
    "\n",
    "    dataTitle=\"Data values: (\"+Xname+\",\"+Yname+\")\\n\"\n",
    "    Group0txt=\"Group0\\n\"\n",
    "    Group1txt=\"Group1\\n\"\n",
    "    for a in Group0:\n",
    "        Group0txt=Group0txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "        \n",
    "    for a in Group1:\n",
    "        Group1txt=Group1txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "\n",
    "    \n",
    "    p=os.getcwd()\n",
    "    \n",
    "    \n",
    "    #save all info into txt\n",
    "    #print(jokeid)\n",
    "    txtName=\"./jokeoutput/2D/\"+str(jokeid)+\".txt\"\n",
    "\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(dataTitle+Group0txt+Group1txt)\n",
    "    f.close()\n",
    "    \n",
    "#     print(jokeid)\n",
    "#     print (model.cluster_centers_)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(x, y, c=model.labels_.astype(float))\n",
    "    plt.title(\"Joke Name: \"+str(jokeid))\n",
    "    plt.xlabel(Xname)\n",
    "    plt.ylabel(Yname)\n",
    "    \n",
    "    pngName=\"./jokeoutput/2D/\"+str(jokeid)+\".png\"\n",
    "    \n",
    "    #remove the existing png file\n",
    "    if os.path.isfile(pngName):\n",
    "        os.remove(pngName) \n",
    "    \n",
    "    #save as png file\n",
    "    plt.savefig(pngName)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#this function will split data into 2 groups by using 4 features\n",
    "def clusterDataIn4D(Info_arr):\n",
    "    #replace all the '/' to '-' since it will mess up with path of windows\n",
    "    jokeid=Info_arr[0].jokeName.replace('/','-')\n",
    "    data=[]\n",
    "    x,y,z,h=[],[],[],[]\n",
    "    performanceName=[]\n",
    "    Xname,Yname='',''\n",
    "    \n",
    "    #get all intensity,pitch,std intensity,std pitch\n",
    "    for joke in Info_arr:\n",
    "        X=joke.intensity\n",
    "        Y=joke.pitch\n",
    "        Z=joke.stinten\n",
    "        H=joke.stpit\n",
    "        data.append((X,Y,Z,H))\n",
    "        performanceName.append(joke.performance)\n",
    "        x.append(X)\n",
    "        y.append(Y)\n",
    "        z.append(Z)\n",
    "        h.append(H)\n",
    "        Xname=\"intensity\"\n",
    "        Yname=\"pitch\"\n",
    "        Zname=\"std intensity\"\n",
    "        Hname=\"std pitch\"\n",
    "\n",
    "    \n",
    "    #if data set is smaller than 2, we cannot split them into 2groups\n",
    "    if(len(data)<2):\n",
    "        return \n",
    "        \n",
    "    # spilt them into 2 group\n",
    "        \n",
    "    model = KMeans(n_clusters=2)\n",
    "\n",
    "    # Note I'm scaling the data to normalize it! Important for good results.\n",
    "    model = model.fit(scale(data))\n",
    "\n",
    "    # We can look at the clusters each data point was assigned to\n",
    "\n",
    "    \n",
    "    count=0\n",
    "    Group0=[]\n",
    "    Group1=[]\n",
    "    for i in data:\n",
    "        #print(\"performance Name: \"+str(performanceName[count])+\"\\t\",\"Data values: \"+str(i)+\"\\t\",\"Group ID: \"+str(model.labels_[count]))  \n",
    "        if(model.labels_[count]==0):\n",
    "            Group0.append((performanceName[count],str(i)))\n",
    "        else:\n",
    "            Group1.append((performanceName[count],str(i)))\n",
    "        count+=1\n",
    "    \n",
    "    dataTitle=\"Data values: (\"+Xname+\",\"+Yname+\",\"+Zname+\",\"+Hname+\")\\n\"\n",
    "    Group0txt=\"Group0\\n\"\n",
    "    Group1txt=\"Group1\\n\"\n",
    "    for a in Group0:\n",
    "        Group0txt=Group0txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "        \n",
    "    for a in Group1:\n",
    "        Group1txt=Group1txt+\"performance Name: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "\n",
    "    \n",
    "    p=os.getcwd()\n",
    "    \n",
    "    \n",
    "    #save all info into txt\n",
    "    txtName=\"./jokeoutput/4D/\"+str(jokeid)+\".txt\"\n",
    "\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(dataTitle+Group0txt+Group1txt)\n",
    "    f.close()\n",
    "    \n",
    "#     print(jokeid)\n",
    "#     print (model.cluster_centers_)\n",
    "\n",
    "\n",
    "#this function will split data into 2 groups by using 6 features\n",
    "def clusterDataIn8D(Info_arr):\n",
    "    #replace all the '/' to '-' since it will mess up with path of windows\n",
    "    jokeid=Info_arr[0].jokeName.replace('/','-')\n",
    "    data=[]\n",
    "    x,y,z,d,e,f,g,h=[],[],[],[],[],[],[],[]\n",
    "    performanceName=[]\n",
    "    Xname,Yname='',''\n",
    "    \n",
    "    #get all intensity,pitch,std intensity,std pitch\n",
    "    for joke in Info_arr:\n",
    "        X=joke.intensity\n",
    "        Y=joke.pitch\n",
    "        Z=joke.stinten\n",
    "        D=joke.stpit\n",
    "        E=joke.max_inten\n",
    "        F=joke.min_inten\n",
    "        G=joke.max_pitch\n",
    "        H=joke.min_pitch\n",
    " \n",
    "        data.append((X,Y,Z,D,E,F,G,H))\n",
    "        performanceName.append(joke.performance+\"----Joke ID: \"+str(joke.id))\n",
    "        x.append(X)\n",
    "        y.append(Y)\n",
    "        z.append(Z)\n",
    "        d.append(d)\n",
    "        e.append(E)\n",
    "        f.append(F)\n",
    "        g.append(G)\n",
    "        h.append(H)\n",
    "        \n",
    "        \n",
    "#         print(E,F)\n",
    "        \n",
    "        Xname=\"intensity\"\n",
    "        Yname=\"pitch\"\n",
    "        Zname=\"std intensity\"\n",
    "        Dname=\"std pitch\"\n",
    "        Ename=\"max inten\"\n",
    "        Fname=\"min inten\"\n",
    "        Gname=\"max pitch\"\n",
    "        Hname=\"min pitch\"\n",
    "\n",
    "    \n",
    "    #if data set is smaller than 2, we cannot split them into 2groups\n",
    "    if(len(data)<2):\n",
    "        return \n",
    "        \n",
    "    # spilt them into 2 group\n",
    "        \n",
    "    model = KMeans(n_clusters=2)\n",
    "\n",
    "    # Note I'm scaling the data to normalize it! Important for good results.\n",
    "    model = model.fit(scale(data))\n",
    "\n",
    "    # We can look at the clusters each data point was assigned to\n",
    "\n",
    "    \n",
    "    count=0\n",
    "    Group0=[]\n",
    "    Group1=[]\n",
    "    for i in data:\n",
    "        #print(\"performance Name: \"+str(performanceName[count])+\"\\t\",\"Data values: \"+str(i)+\"\\t\",\"Group ID: \"+str(model.labels_[count]))  \n",
    "        if(model.labels_[count]==0):\n",
    "            Group0.append((performanceName[count],str(i)))\n",
    "        else:\n",
    "            Group1.append((performanceName[count],str(i)))\n",
    "        count+=1\n",
    "    \n",
    "    dataTitle=\"Data values: (\"+Xname+\",\"+Yname+\",\"+Zname+\",\"+Dname+\",\"+Ename+\",\"+Fname+\",\"+Gname+\",\"+Hname+\")\\n\"\n",
    "    Group0txt=\"Group0\\n\"\n",
    "    Group1txt=\"Group1\\n\"\n",
    "    for a in Group0:\n",
    "        Group0txt=Group0txt+\"performance Name and Joke ID: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "        \n",
    "    for a in Group1:\n",
    "        Group1txt=Group1txt+\"performance Name and Joke ID: \"+str(a[0])+\"  \"+\"Data values: \"+str(a[1])+\"\\n\"\n",
    "\n",
    "    \n",
    "    p=os.getcwd()\n",
    "    \n",
    "    \n",
    "    #save all info into txt\n",
    "    txtName=\"./jokeoutput/8D/\"+str(jokeid)+\".txt\"\n",
    "\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(dataTitle+Group0txt+Group1txt)\n",
    "    f.close()\n",
    "    \n",
    "#     print(jokeid)\n",
    "#     print (model.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def overallCorrelation(combine_joke_dict):\n",
    "    x,y,z,d,e,f,g,h=[],[],[],[],[],[],[],[]\n",
    "    midjokeRating=[]\n",
    "    for i in combine_joke_dict:\n",
    "        arr=combine_joke_dict[i]\n",
    "        for joke in arr:\n",
    "            x.append(joke.intensity)\n",
    "            y.append(joke.pitch)\n",
    "            z.append(joke.stinten)\n",
    "            d.append(joke.stpit)\n",
    "            e.append(joke.max_inten)\n",
    "            f.append(joke.min_inten)\n",
    "            g.append(joke.max_pitch)\n",
    "            h.append(joke.min_pitch)\n",
    "            midjokeRating.append(joke.midjoke)\n",
    "    \n",
    "    arr=[x,y,z,d,e,f,g,h]\n",
    "    result={}\n",
    "    var=['intensity','pitch','stdIntensity','stdPitch','maxIntensity','minIntensity','maxPitch','minPitch']\n",
    "    length=len(var)\n",
    "    \n",
    "    pontential=\"The correlation coefficient are higher than 7:\\n\"\n",
    "    \n",
    "    for i in range(0,length-1):\n",
    "        for j in range(i+1,length):\n",
    "            #save txt result\n",
    "            key=var[i]+'-'+var[j]\n",
    "            result[key]=pearsonr(arr[i],arr[j])[0]\n",
    "            if(abs(result[key])>0.7):\n",
    "                pontential=pontential+key+\": \"+str(result[key])+\"\\n\"\n",
    "            \n",
    "            #draw plot\n",
    "            path=\"./jokeoutput/overall-correlation/\"+key+\".png\"            \n",
    "            draw2Dplot(var[i],var[j],arr[i],arr[j],path,midjokeRating)\n",
    "\n",
    "    print(len(result))\n",
    "    txtName=\"./jokeoutput/overall-correlation/correlation.txt\"\n",
    "    \n",
    "    output=''\n",
    "    for n in result:\n",
    "        output=output+n+\": \"+str(result[n])+\"\\n\"\n",
    "\n",
    "    output=output+\"\\n\\n\"+pontential\n",
    "    if os.path.isfile(txtName):\n",
    "        os.remove(txtName) \n",
    "    f = open(txtName, \"a\")\n",
    "    f.write(output)\n",
    "    f.close()\n",
    "    \n",
    "def jokeWiseCorrelation(combine_joke_dict):\n",
    "    x,y,z,d,e,f,g,h=[],[],[],[],[],[],[],[]\n",
    "    midjokeRating=[]\n",
    "    var=['intensity','pitch','stdIntensity','stdPitch','maxIntensity','minIntensity','maxPitch','minPitch']\n",
    "    length=len(var)\n",
    "    pontential=\"The correlation coefficient are higher than 7:\\n\"\n",
    "    for i in combine_joke_dict:\n",
    "        arr=combine_joke_dict[i]\n",
    "        x.clear()\n",
    "        y.clear()\n",
    "        z.clear()\n",
    "        d.clear()\n",
    "        e.clear()\n",
    "        f.clear()\n",
    "        g.clear()\n",
    "        h.clear()\n",
    "        midjokeRating.clear()\n",
    "        jokename=''\n",
    "        for joke in arr:\n",
    "            x.append(joke.intensity)\n",
    "            y.append(joke.pitch)\n",
    "            z.append(joke.stinten)\n",
    "            d.append(joke.stpit)\n",
    "            e.append(joke.max_inten)\n",
    "            f.append(joke.min_inten)\n",
    "            g.append(joke.max_pitch)\n",
    "            h.append(joke.min_pitch) \n",
    "            jokename=joke.jokeName\n",
    "            midjokeRating.append(joke.midjoke)\n",
    "            \n",
    "        jokename=jokename.replace('/','-')\n",
    "        arr=[x,y,z,d,e,f,g,h]\n",
    "        result={}\n",
    "        dirPath=\"./jokeoutput/jokewise-correlation/\"+jokename\n",
    "                \n",
    "        for i in range(0,length-1):\n",
    "            for j in range(i+1,length):\n",
    "                #save txt result\n",
    "                key=var[i]+'-'+var[j]\n",
    "#                 print(len(arr[i]),len(arr[j]))\n",
    "                if(len(arr[i])<10):\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "                else:    \n",
    "                    if not os.path.exists(dirPath):\n",
    "                        os.mkdir(dirPath)\n",
    "                    result[key]=pearsonr(arr[i],arr[j])[0]\n",
    "                    if(abs(result[key])>0.7):\n",
    "                        pontential=pontential+key+\": \"+str(result[key])+\"\\n\"\n",
    "                    #draw plot\n",
    "                    path=dirPath+\"/\"+key+\".png\"           \n",
    "#                     print(path)\n",
    "                    draw2Dplot(var[i],var[j],arr[i],arr[j],path,midjokeRating)\n",
    "\n",
    "        txtName=dirPath+\"/correlation.txt\"\n",
    "\n",
    "        output=''\n",
    "        for n in result:\n",
    "            output=output+n+\": \"+str(result[n])+\"\\n\"\n",
    "        if(output==''):\n",
    "            continue\n",
    "        output=output+\"\\n\\n\"+pontential\n",
    "        if os.path.isfile(txtName):\n",
    "            os.remove(txtName) \n",
    "        file = open(txtName, \"a\")\n",
    "        file.write(output)\n",
    "        file.close()\n",
    "        pontential=\"The correlation coefficient are higher than 7:\\n\"\n",
    "    \n",
    "def draw2Dplot(Xname,Yname,x,y,path,midjokeRating):\n",
    "    fig=plt.figure(figsize=(10,6))\n",
    "#     plt.scatter(x, y)\n",
    "    plt.title(Xname+\"-\"+Yname)\n",
    "    plt.xlabel(Xname)\n",
    "    plt.ylabel(Yname)\n",
    "    for i in range(0,len(x)):\n",
    "        if(midjokeRating[i]==1):\n",
    "            plt.scatter(x[i],y[i],marker=\"^\",color='r',label='Blue stars')\n",
    "        elif(midjokeRating[i]==0):\n",
    "            plt.scatter(x[i],y[i],marker=\"x\",color='b',label='Red stars')\n",
    "            \n",
    "    red_patch = mpatches.Patch(color='red', label='mid joke happened')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='mid joke did not happen')\n",
    "    plt.legend(handles=[red_patch,blue_patch])\n",
    "    \n",
    "    pngName=path\n",
    "    #remove the existing png file\n",
    "    if os.path.isfile(pngName):\n",
    "        os.remove(pngName) \n",
    "    #save as png file\n",
    "    plt.savefig(pngName)\n",
    "#     plt.show()\n",
    "    plt.close(fig) \n",
    "\n",
    "def humanAnnotation(path):\n",
    "    humanRateDict={}\n",
    "    f = open(r''+path, \"r\")\n",
    "    lines = f.readlines()\n",
    "    value=0\n",
    "    key=''\n",
    "    for line in lines:\n",
    "        if(\".eaf\" in line):\n",
    "            if(key is not ''):\n",
    "                humanRateDict[key]=value\n",
    "                key=''\n",
    "                value=0\n",
    "                \n",
    "            arr=line.split('\\\\')\n",
    "            if(\"\\\\Annotations\\\\\" not in line):\n",
    "                key=arr[-2]+'-'+arr[-1].split('.')[-2].split('_')[-1]\n",
    "            else:\n",
    "                key=arr[-3]+'-'+arr[-1].split('.')[-2].split('_')[-1]\n",
    "        elif(not line.isspace()):\n",
    "            value=1\n",
    "            \n",
    "    if(key not in humanRateDict):\n",
    "        humanRateDict[key]=value\n",
    "#     for x in humanRateDict:\n",
    "#         print(x,humanRateDict[x])\n",
    "    return humanRateDict\n",
    "\n",
    "def drawBoxPlot(a,b,title,path):\n",
    "    data=[a,b]\n",
    "    fig1, ax1 = plt.subplots(figsize=(10,10))\n",
    "    ax1.set_title(title)\n",
    "    red_square = dict(markerfacecolor='r', marker='s')\n",
    "    ax1.boxplot(data,flierprops=red_square)\n",
    "    plt.xticks([1, 2], ['Laughter not happen(0)', 'Laughter happen(1)'])\n",
    "    pngName=path+title+\".png\"\n",
    "    plt.savefig(pngName)\n",
    "    plt.close()\n",
    "\n",
    "def overallBoxPlot(combine_joke_dict):\n",
    "    group0=[]\n",
    "    group1=[]\n",
    "    for i in combine_joke_dict:\n",
    "            arr=combine_joke_dict[i]\n",
    "            for joke in arr:\n",
    "                val=joke.midjoke\n",
    "                if(val==0):\n",
    "                    group0.append(joke)\n",
    "                else:\n",
    "                    group1.append(joke)\n",
    "    name=['intensity,dB','pitch,Hz','std Intensity,dB','std Pitch,Hz','max_intensity,dB','min_intensity,dB','max_pitch,Hz','min_pitch,Hz']\n",
    "    var=['intensity','pitch','stinten','stpit','max_inten','min_inten','max_pitch','min_pitch']\n",
    "    path=\"./jokeoutput/overall-boxplot/\"\n",
    "    \n",
    "    index=0\n",
    "    for feature in var:\n",
    "        a=[]\n",
    "        b=[]\n",
    "        for joke in group0:\n",
    "            a.append(getattr(joke,feature))\n",
    "        for joke in group1:\n",
    "            b.append(getattr(joke,feature))\n",
    "        drawBoxPlot(a,b,name[index],path) \n",
    "        index=index+1\n",
    "\n",
    "def jokeWiseBoxPlot(combine_joke_dict):\n",
    "    for i in combine_joke_dict:\n",
    "        arr=combine_joke_dict[i]\n",
    "        if(len(arr)<10):\n",
    "            continue\n",
    "        group0=[]\n",
    "        group1=[]\n",
    "        jokename=''\n",
    "        for joke in arr:\n",
    "            val=joke.midjoke\n",
    "            jokename=joke.jokeName.replace('/','-')\n",
    "            if(val==0):\n",
    "                group0.append(joke)\n",
    "            else:\n",
    "                group1.append(joke)\n",
    "        name=['intensity,dB','pitch,Hz','std Intensity,dB','std Pitch,Hz','max_intensity,dB','min_intensity,dB','max_pitch,Hz','min_pitch,Hz']\n",
    "        var=['intensity','pitch','stinten','stpit','max_inten','min_inten','max_pitch','min_pitch']\n",
    "        path=\"./jokeoutput/jokewise-boxplot/\"+jokename\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "            \n",
    "        index=0\n",
    "        for feature in var:\n",
    "            a=[]\n",
    "            b=[]\n",
    "            for joke in group0:\n",
    "                a.append(getattr(joke,feature))\n",
    "            for joke in group1:\n",
    "                b.append(getattr(joke,feature))\n",
    "            drawBoxPlot(a,b,name[index],path+'/') \n",
    "            index=index+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\college\\CapstoneWork\\MidJokeMachineLearning\\joke_name_matching\n",
      "E:\\college\\CapstoneWork\\\\joke_name_matchingMid-Joke Laughter Annotations\\humanAnnotations.txt\n",
      "False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\college\\\\CapstoneWork\\\\\\\\joke_name_matchingMid-Joke Laughter Annotations\\\\humanAnnotations.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-790eb11cfe6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-790eb11cfe6b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misExist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m     \u001b[0mhumanRateDict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhumanAnnotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr''\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpath1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m     \u001b[0mjokeNameDict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetJokeNameForEachPerformance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[1;31m#i am using directory pitch_inten_avg_std_minmax since it is the test contain most information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-b1d46848e0c6>\u001b[0m in \u001b[0;36mhumanAnnotation\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhumanAnnotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mhumanRateDict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr''\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\college\\\\CapstoneWork\\\\\\\\joke_name_matchingMid-Joke Laughter Annotations\\\\humanAnnotations.txt'"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from os import system\n",
    "import pydot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from combo.models.classifier_comb import SimpleClassifierAggregator\n",
    "from combo.utils.data import evaluate_print\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "rbfData=[]\n",
    "\n",
    "\n",
    "def leaveOnePerformanceOut(combine_joke_dict,perName):\n",
    "    train_data={}\n",
    "    valid_data={}\n",
    "    for key in combine_joke_dict:\n",
    "        jokearr=combine_joke_dict[key]\n",
    "        for joke in jokearr:\n",
    "            if(joke.performance==perName):\n",
    "                if(key in valid_data):\n",
    "                    valid_data[key].append(joke)\n",
    "                else:\n",
    "                    valid_data[key]=[joke]\n",
    "            else:\n",
    "                if(key in train_data):\n",
    "                    train_data[key].append(joke)\n",
    "                else:\n",
    "                    train_data[key]=[joke]\n",
    "    return train_data,valid_data\n",
    "\n",
    "def appendData(joke):\n",
    "    singleSample=[]\n",
    "    singleSample.append(joke.intensity)\n",
    "#     singleSample.append(joke.pitch)\n",
    "    singleSample.append(joke.stinten)\n",
    "    singleSample.append(joke.stpit)\n",
    "    singleSample.append(joke.max_inten)\n",
    "    singleSample.append(joke.min_inten)\n",
    "    singleSample.append(joke.max_pitch)\n",
    "    singleSample.append(joke.min_pitch)\n",
    "    singleSample.append(joke.intensityRange)\n",
    "    singleSample.append(joke.pitchRange)\n",
    "    return singleSample\n",
    "\n",
    "def decision_tree(train_data,valid_data,overall):\n",
    "    features=['intensity','pitch','stdIntensity','stdPitch','maxIntensity','minIntensity','maxPitch','minPitch','intensityRange','pitchRange']\n",
    "    X=[]\n",
    "    Y=[]\n",
    "\n",
    "    for i in train_data:\n",
    "        arr=train_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            X.append(singleSample)\n",
    "            Y.append(joke.midjoke)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X, Y)\n",
    "    \n",
    "#     tree.plot_tree(clf.fit(X, Y)) \n",
    "#     dotfile = open(\"./jokeoutput/decision-tree/dtree2.dot\", 'w')\n",
    "    \n",
    "#     tree.export_graphviz(clf, out_file = dotfile, feature_names = features)\n",
    "#     dotfile.close()\n",
    "#     (graph,) = pydot.graph_from_dot_file('./jokeoutput/decision-tree/dtree2.dot')\n",
    "#     graph.write_png('./jokeoutput/decision-tree/result.png')\n",
    "    \n",
    "    \n",
    "    validX=[]\n",
    "    validY=[]\n",
    "    \n",
    "    perName=\"\"\n",
    "    for i in valid_data:\n",
    "        arr=valid_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            validX.append(singleSample)\n",
    "            validY.append(joke.midjoke)\n",
    "            perName=joke.performance\n",
    "    \n",
    "    clf2 = RandomForestClassifier(n_estimators=11)\n",
    "    clf2 = clf2.fit(X, Y)\n",
    "    if(overall==1):   \n",
    "        result1=\"onetree: \"+str(clf.score(validX, validY))\n",
    "        \n",
    "        result2=\"random forest: \"+str(clf2.score(validX, validY))\n",
    "        txtFile = open(\"./jokeoutput/decision-tree/tree_result.txt\", 'a')\n",
    "        txtFile.write(perName+'\\n'+result1+'\\n\\n')\n",
    "        txtFile.close()\n",
    "        txtFile = open(\"./jokeoutput/decision-tree/forest_result.txt\", 'a')\n",
    "        txtFile.write(perName+'\\n'+result2+'\\n\\n')\n",
    "        txtFile.close()\n",
    "    #     print(result1+'\\n'+result2)\n",
    "\n",
    "    #     evaluate_print('Decision Tree        |', validY, clf.predict(validX))\n",
    "    #     evaluate_print('Random Forest       |', validY, clf2.predict(validX))\n",
    "    \n",
    "    return clf,clf2,clf.score(validX, validY),clf2.score(validX, validY)\n",
    "\n",
    "    \n",
    "#for KNN, i have train_data1,train_data2,valid_data. Since I dont know what is the best number for K.\n",
    "#i use train_data1 to train model, then I have one set of performance which is train_data2 to get the Accuracy.\n",
    "#in the end, i apply the best K i found into valid_data to get the final Accuracy\n",
    "def KNN(train_data1,train_data2,valid_data,overall):\n",
    "\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    perName=\"\"\n",
    "    for i in train_data1:\n",
    "        arr=train_data1[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            X.append(singleSample)\n",
    "            Y.append(joke.midjoke)\n",
    "    \n",
    "    X2=[]\n",
    "    Y2=[]\n",
    "    for i in train_data2:\n",
    "        arr=train_data2[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            X2.append(singleSample)\n",
    "            Y2.append(joke.midjoke)\n",
    "\n",
    "    maxscore=0\n",
    "    bestclf=KNeighborsClassifier(n_neighbors=3)\n",
    "    bestclf.fit(X, Y)\n",
    "    for n in range(3,int(len(train_data1)/2),2):\n",
    "        clf = KNeighborsClassifier(n_neighbors=n)\n",
    "        clf.fit(X, Y)\n",
    "        score=clf.score(X2, Y2)\n",
    "        if(score>maxscore):\n",
    "            bestclf=clf\n",
    "            bestN=n\n",
    "            maxscore=score\n",
    "    \n",
    "    clf=bestclf\n",
    "#     print(maxscore,bestN)\n",
    "    validX=[]\n",
    "    validY=[]\n",
    "    \n",
    "    for i in valid_data:\n",
    "        arr=valid_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            validX.append(singleSample)\n",
    "            validY.append(joke.midjoke)\n",
    "            perName=joke.performance\n",
    "#     print(validX)\n",
    "#     print(validY)\n",
    "    \n",
    "    if(overall==1):  \n",
    "        result=perName+\"\\nBest Neighbor Number: \"+str(bestN)+'\\n'\n",
    "        result=result+\"KNN Accuracy: \"+str(bestclf.score(validX, validY))+\"\\n\\n\"\n",
    "    #     print(result)\n",
    "\n",
    "    #     evaluate_print('KNN        |', validY, clf.predict(validX))\n",
    "\n",
    "        txtFile = open(\"./jokeoutput/KNN/result.txt\", 'a')\n",
    "        txtFile.write(result)\n",
    "        txtFile.close()\n",
    "        \n",
    "    return clf,bestclf.score(validX, validY)\n",
    "\n",
    "def SVC_Algorithm(train_data,valid_data,overall,normalize):\n",
    "    global rbfData\n",
    "\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    \n",
    "    for i in train_data:\n",
    "        arr=train_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            X.append(singleSample)\n",
    "            Y.append(joke.midjoke)\n",
    "\n",
    "            \n",
    "    if(not(1 in Y and 0 in Y)):\n",
    "        print(\"SVC cannot be generate due to no enough data\")\n",
    "        return None,None,None,None,None,None\n",
    "    \n",
    "    \n",
    "    validX=[]\n",
    "    validY=[]\n",
    "    perName=''\n",
    "    for i in valid_data:\n",
    "        arr=valid_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "\n",
    "            validX.append(singleSample)\n",
    "            validY.append(joke.midjoke)\n",
    "            perName=joke.performance\n",
    "        \n",
    "    gamma_val=0.00001\n",
    "    c_val=15000\n",
    "    if(normalize=='standard'):\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        scaler2 = StandardScaler()\n",
    "        validX = scaler2.fit_transform(validX)\n",
    "        gamma_val=.001\n",
    "        c_val=1000\n",
    "#         print(\"X: \"+str(X))\n",
    "#         print(\"VX: \"+str(validX))\n",
    "        \n",
    "    rbfclf = SVC(kernel='rbf',C=c_val,gamma=gamma_val)\n",
    "    rbfclf.fit(X, Y)\n",
    "    \n",
    "    linearclf = SVC(kernel='linear')\n",
    "    linearclf.fit(X, Y)\n",
    "    \n",
    "    polyclf = SVC(kernel='poly',degree=8)\n",
    "    polyclf.fit(X, Y)\n",
    "    \n",
    "    \n",
    "    score1,score2,score3=0,0,0\n",
    "    \n",
    "    score1=rbfclf.score(validX, validY)\n",
    "    result1=\"RBF accuracy:\" +str(score1)\n",
    "    #     print(result1)\n",
    "    score2=linearclf.score(validX, validY)\n",
    "    result2=\"Linear accuracy:\" +str(score2)\n",
    "    #     print(result2)\n",
    "    score3=polyclf.score(validX, validY)\n",
    "    result3=\"Polynomial accuracy:\" +str(score3)\n",
    "    \n",
    "    \n",
    "    for i in valid_data:\n",
    "        arr=valid_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            joke.predictY=polyclf.predict([singleSample])[0]\n",
    "            rbfData.append([joke.performance,joke.id,joke.jokeName,joke.midjoke,joke.predictY])\n",
    "    if(overall==1):\n",
    "    #     print(result3)\n",
    "    #     evaluate_print('RBF        |', validY, rbfclf.predict(validX))\n",
    "    #     evaluate_print('Linear        |', validY, linearclf.predict(validX))\n",
    "    #     evaluate_print('Polynomial        |', validY, polyclf.predict(validX))\n",
    "        txtFile = open(\"./jokeoutput/SVC/RBF_result.txt\", 'a')\n",
    "        txtFile.write(perName+\"\\n\"+result1+'\\n\\n')\n",
    "        txtFile.close()\n",
    "\n",
    "        txtFile = open(\"./jokeoutput/SVC/Linear_result.txt\", 'a')\n",
    "        txtFile.write(perName+\"\\n\"+result2+'\\n\\n')\n",
    "        txtFile.close()\n",
    "\n",
    "        txtFile = open(\"./jokeoutput/SVC/Polynomial_result.txt\", 'a')\n",
    "        txtFile.write(perName+\"\\n\"+result3+'\\n\\n')\n",
    "        txtFile.close()\n",
    "        \n",
    "    \n",
    "    return rbfclf,polyclf,linearclf,score1,score2,score3\n",
    "\n",
    "\n",
    "def Ensemble_models(classifiers,train_data,valid_data,overall):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    \n",
    "    for i in train_data:\n",
    "        arr=train_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            X.append(singleSample)\n",
    "            Y.append(joke.midjoke)\n",
    "            \n",
    "    \n",
    "    validX=[]\n",
    "    validY=[]\n",
    "    perName=''\n",
    "    for i in valid_data:\n",
    "        arr=valid_data[i]\n",
    "        for joke in arr:\n",
    "            singleSample=appendData(joke)\n",
    "            validX.append(singleSample)\n",
    "            validY.append(joke.midjoke)\n",
    "            perName=joke.performance\n",
    "\n",
    "    \n",
    "    clf1 = SimpleClassifierAggregator(classifiers, method='average')\n",
    "    clf1.fit(X, Y)\n",
    "#     evaluate_print('Combination by avg   |', validY, clf1.predict(validX))\n",
    "    \n",
    "        # combine by median\n",
    "#     clf2 = SimpleClassifierAggregator(classifiers, method='median')\n",
    "#     clf2.fit(X, Y)\n",
    "#     evaluate_print('Combination by median   |', validY, clf2.predict(validX))\n",
    "    \n",
    "    clf3 = SimpleClassifierAggregator(classifiers, method='average')\n",
    "    clf3.fit(X, Y)\n",
    "    y_predicted = clf3.predict(validX)\n",
    "    \n",
    "    diff=0\n",
    "    for y in zip(validY,y_predicted):\n",
    "        diff=diff+abs(y[0]-y[1])\n",
    "    accuracy=1-diff/len(validY)\n",
    "    \n",
    "    if(overall==1):\n",
    "        result=\"Ensemble accuracy: \"+ str(accuracy)\n",
    "        txtFile = open(\"./jokeoutput/EnsembleModel/result.txt\", 'a')\n",
    "        txtFile.write(perName+\"\\n\"+result+'\\n\\n')\n",
    "        txtFile.close()\n",
    "    \n",
    "    return clf1,accuracy\n",
    "\n",
    "def clear_file():\n",
    "    txtNames=[\"./jokeoutput/EnsembleModel/result.txt\",\"./jokeoutput/SVC/Polynomial_result.txt\",\n",
    "             \"./jokeoutput/SVC/Linear_result.txt\",\"./jokeoutput/SVC/RBF_result.txt\",\n",
    "             \"./jokeoutput/KNN/result.txt\",\"./jokeoutput/decision-tree/forest_result.txt\",\n",
    "             \"./jokeoutput/decision-tree/tree_result.txt\"]\n",
    "    for txtName in txtNames:\n",
    "        if os.path.isfile(txtName):\n",
    "            os.remove(txtName) \n",
    "            \n",
    "def checkWrongClassify(valid_data,forest,knnModel,rbf,poly,linear):\n",
    "    for index in valid_data:\n",
    "        for joke in valid_data[index]:\n",
    "            key=str(joke.performance)+\"------\"+str(joke.jokeName)\n",
    "            val=str(joke.performance)+\"------\"+str(joke.jokeName)+\"------JokeID: \"+str(joke.id)\n",
    "            singleSample=appendData(joke)\n",
    "            if(joke.midjoke==0):\n",
    "                if(forest!=None and forest.predict([singleSample])==1):\n",
    "                    if('forest' not in notLaughButClassifyLaugh):\n",
    "                        notLaughButClassifyLaugh['forest']=[val]\n",
    "                    else:\n",
    "                        notLaughButClassifyLaugh['forest'].append(val)\n",
    "                    if(key not in allWrongClassify):\n",
    "                        allWrongClassify[key]=1\n",
    "                    else:\n",
    "                        allWrongClassify[key]+=1\n",
    "                if(knnModel!=None and knnModel.predict([singleSample])==1):\n",
    "                    if('knnModel' not in notLaughButClassifyLaugh):\n",
    "                        notLaughButClassifyLaugh['knnModel']=[val]\n",
    "                    else:\n",
    "                        notLaughButClassifyLaugh['knnModel'].append(val)\n",
    "                    if(key not in allWrongClassify):\n",
    "                        allWrongClassify[key]=1\n",
    "                    else:\n",
    "                        allWrongClassify[key]+=1\n",
    "                if(rbf!=None and rbf.predict([singleSample])==1):\n",
    "                    if('rbf' not in notLaughButClassifyLaugh):\n",
    "                        notLaughButClassifyLaugh['rbf']=[val]\n",
    "                    else:\n",
    "                        notLaughButClassifyLaugh['rbf'].append(val)\n",
    "                    if(key not in allWrongClassify):\n",
    "                        allWrongClassify[key]=1\n",
    "                    else:\n",
    "                        allWrongClassify[key]+=1\n",
    "                if(poly!=None and poly.predict([singleSample])==1):\n",
    "                    if('poly' not in notLaughButClassifyLaugh):\n",
    "                        notLaughButClassifyLaugh['poly']=[val]\n",
    "                    else:\n",
    "                        notLaughButClassifyLaugh['poly'].append(val)\n",
    "                    if(key not in allWrongClassify):\n",
    "                        allWrongClassify[key]=1\n",
    "                    else:\n",
    "                        allWrongClassify[key]+=1\n",
    "                if(linear!=None and linear.predict([singleSample])==1):\n",
    "                    if('linear' not in notLaughButClassifyLaugh):\n",
    "                        notLaughButClassifyLaugh['linear']=[val]\n",
    "                    else:\n",
    "                        notLaughButClassifyLaugh['linear'].append(val)\n",
    "                    if(key not in allWrongClassify):\n",
    "                        allWrongClassify[key]=1\n",
    "                    else:\n",
    "                        allWrongClassify[key]+=1\n",
    "                                      \n",
    "    \n",
    "\n",
    "def over_all_model_test(combine_joke_dict):\n",
    "    global rbfData\n",
    "    rbfData=[]\n",
    "    \n",
    "    perLen=len(perNameDict)\n",
    "    perNames=list(perNameDict.keys())\n",
    "    clear_file()\n",
    "    \n",
    "    treeTotal,forestTotal,rbfTotal,polyTotal,linearTotal,ensembleTotal,KNNtotal=0,0,0,0,0,0,0\n",
    "    \n",
    "    count=0\n",
    "    normlize=\"none\"\n",
    "    print(\"normlize is \"+normlize)\n",
    "    print(\"Total performances: \"+str(len(perNames)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for perName in perNames:\n",
    "        print(\"validing \"+perName)\n",
    "        \n",
    "        index=(count+1)%perLen\n",
    "        train_data2_perName=perNames[index]\n",
    "        \n",
    "        train_data,valid_data=leaveOnePerformanceOut(combine_joke_dict,perName)\n",
    "        train_data1,train_data2=leaveOnePerformanceOut(train_data,train_data2_perName)\n",
    "        \n",
    "        tree,forest,treeScore,forestScore=decision_tree(train_data,valid_data,1)\n",
    "\n",
    "        rbf,poly,linear,rbfScore,polyScore,linearScore=SVC_Algorithm(train_data,valid_data,1,normlize)\n",
    "        \n",
    "        \n",
    "        knnModel,KNNscore=KNN(train_data1,train_data2,valid_data,1)\n",
    "        \n",
    "        checkWrongClassify(valid_data,forest,knnModel,rbf,poly,linear)\n",
    "        classifier=[knnModel,linear,forest]\n",
    "#         if(rbf!=None and poly!=None and linear!=None):\n",
    "#             classifier=[forest,knnModel,rbf,poly,linear]\n",
    "#         else:\n",
    "#             classifier=[forest,knnModel]\n",
    "        \n",
    "        Ensemble_clf,ensemble_score= Ensemble_models(classifier,train_data,valid_data,1)\n",
    "        \n",
    "        treeTotal=treeTotal+treeScore\n",
    "        forestTotal=forestTotal+forestScore\n",
    "        rbfTotal=rbfTotal+rbfScore\n",
    "        polyTotal=polyTotal+polyScore\n",
    "        linearTotal=linearTotal+linearScore\n",
    "        ensembleTotal=ensembleTotal+ensemble_score\n",
    "        KNNtotal=KNNtotal+KNNscore\n",
    "        \n",
    "        count=count+1\n",
    "    \n",
    "    \n",
    "    \n",
    "    avgTree=treeTotal/perLen\n",
    "    avgForest=forestTotal/perLen\n",
    "    avgRBF=rbfTotal/perLen\n",
    "    avgPoly=polyTotal/perLen\n",
    "    avglinear=linearTotal/perLen\n",
    "    avgEnsemble=ensembleTotal/perLen\n",
    "    avgKNN=KNNtotal/perLen\n",
    "    \n",
    "    results=[\"avgTree \"+str(avgTree),\"avgForest \"+str(avgForest),\"avgKNN \"+str(avgKNN),\"avgRBF \"+str(avgRBF),\"avgPoly \"+str(avgPoly),\n",
    "            \"avglinear \"+str(avglinear),\"avgEnsemble \"+str(avgEnsemble)]\n",
    "    \n",
    "    final_ouput=\"\"\n",
    "    \n",
    "    for result in results:\n",
    "        final_ouput=final_ouput+result+'\\n'\n",
    "        print(result)\n",
    "    \n",
    "    txtFile = open(\"./jokeoutput/Final_result_of_allModels.txt\", 'w')\n",
    "    txtFile.write(final_ouput)\n",
    "    txtFile.close()\n",
    "    \n",
    "def jokewise_model_test(jokearr):\n",
    "    length=len(jokearr)\n",
    "    if(length<10):\n",
    "        return\n",
    "    \n",
    "    jokedict={}\n",
    "    jokewise_perNameDict={}\n",
    "    \n",
    "    human_rate=[]\n",
    "    jokename=''\n",
    "    for joke in jokearr:  \n",
    "        jokename=joke.jokeName\n",
    "        pername=joke.performance\n",
    "        jokewise_perNameDict[pername]=pername\n",
    "        human_rate.append(joke.midjoke)\n",
    "#         print(jokename,pername)\n",
    "    jokedict[jokename]=jokearr\n",
    "    perLen=len(jokewise_perNameDict)\n",
    "    perNames=list(jokewise_perNameDict.keys())\n",
    "    \n",
    "    print(len(perNames))\n",
    "    \n",
    "    txtpath=\"./jokeoutput/jokewise_all_models/result.txt\"\n",
    "    \n",
    "    txtFile = open(txtpath, 'a')\n",
    "    txtFile.write(jokename+'\\n')\n",
    "    txtFile.write(\"Total performnace for this joke :\"+str(len(perNames))+'\\n')\n",
    "    \n",
    "    treeTotal,forestTotal,rbfTotal,polyTotal,linearTotal,ensembleTotal,KNNtotal=0,0,0,0,0,0,0\n",
    "    \n",
    "    count=0\n",
    "    normlize=\"standard\"\n",
    "    print(\"normlize is \"+normlize)\n",
    "    for perName in jokewise_perNameDict:\n",
    "        print(\"validing \"+perName)\n",
    "        \n",
    "        \n",
    "        index=(count+1)%perLen\n",
    "        train_data2_perName=perNames[index]\n",
    "        \n",
    "        train_data,valid_data=leaveOnePerformanceOut(jokedict,perName)\n",
    "        train_data1,train_data2=leaveOnePerformanceOut(train_data,train_data2_perName)\n",
    "        \n",
    "        tree,forest,treeScore,forestScore=decision_tree(train_data,valid_data,0)\n",
    "\n",
    "        rbf,poly,linear,rbfScore,polyScore,linearScore=SVC_Algorithm(train_data,valid_data,0,normlize)\n",
    "        \n",
    "        \n",
    "        knnModel,KNNscore=KNN(train_data1,train_data2,valid_data,0)\n",
    "\n",
    "        if(rbf!=None and poly!=None and linear!=None):\n",
    "            \n",
    "            classifier=[forest,knnModel,rbf,poly,linear]\n",
    "        else:\n",
    "            classifier=[forest,knnModel]\n",
    "            \n",
    "        Ensemble_clf,ensemble_score= Ensemble_models(classifier,train_data,valid_data,0)\n",
    "        \n",
    "        treeTotal=treeTotal+treeScore\n",
    "        forestTotal=forestTotal+forestScore\n",
    "        if(rbfScore!=None):\n",
    "            rbfTotal=rbfTotal+rbfScore\n",
    "        if(polyScore!=None):\n",
    "            polyTotal=polyTotal+polyScore\n",
    "        if(linearScore!=None):\n",
    "            linearTotal=linearTotal+linearScore\n",
    "        ensembleTotal=ensembleTotal+ensemble_score\n",
    "        KNNtotal=KNNtotal+KNNscore\n",
    "        \n",
    "        count=count+1\n",
    "    \n",
    "    avgTree=treeTotal/perLen\n",
    "    avgForest=forestTotal/perLen\n",
    "    avgRBF=rbfTotal/perLen\n",
    "    avgPoly=polyTotal/perLen\n",
    "    avglinear=linearTotal/perLen\n",
    "    avgEnsemble=ensembleTotal/perLen\n",
    "    avgKNN=KNNtotal/perLen\n",
    "    \n",
    "    results=[\"avgTree \"+str(avgTree),\"avgForest \"+str(avgForest),\"avgKNN \"+str(avgKNN),\"avgRBF \"+str(avgRBF),\"avgPoly \"+str(avgPoly),\n",
    "            \"avglinear \"+str(avglinear),\"avgEnsemble \"+str(avgEnsemble)]\n",
    "    \n",
    "    final_ouput=\"\"\n",
    "    \n",
    "    for result in results:\n",
    "        final_ouput=final_ouput+result+'\\n'\n",
    "        print(result)\n",
    "    \n",
    "\n",
    "    txtFile.write(final_ouput+'\\n\\n')\n",
    "    txtFile.close()\n",
    "    \n",
    "def recordBadClassification():\n",
    "    path=\"./jokeoutput//wrongClassification/\"\n",
    "    for key in notLaughButClassifyLaugh:\n",
    "        filename=path+key+'.txt'\n",
    "        output=key+'\\n'\n",
    "        for val in notLaughButClassifyLaugh[key]:\n",
    "            output=output+val+'\\n'\n",
    "        txtFile = open(filename, 'w')\n",
    "        txtFile.write(output)\n",
    "        txtFile.close()\n",
    "        \n",
    "    filename=path+'combinedResult.txt'\n",
    "    output=\"combined Result\\n\"\n",
    "    \n",
    "    for key, value in reversed(sorted(allWrongClassify.items(), key=lambda item: item[1])):\n",
    "        output=output+key+\" : \"+str(value)+'\\n'\n",
    "        \n",
    "    txtFile = open(filename, 'w')\n",
    "    txtFile.write(output)\n",
    "    txtFile.close()\n",
    "\n",
    "\n",
    "    \n",
    "def main():\n",
    "    global jokeNameDict\n",
    "    global humanRateDict\n",
    "    global perNameDict\n",
    "    global notLaughButClassifyLaugh\n",
    "    global allWrongClassify\n",
    "    notLaughButClassifyLaugh={}\n",
    "    allWrongClassify={}\n",
    "    perNameDict={}\n",
    "    cwd=os.getcwd()\n",
    "    print(cwd)\n",
    "    path2=cwd+'\\joke_name_matching'\n",
    "    path3=cwd+'\\jokeinput'\n",
    "    path1=cwd.replace('MidJokeMachineLearning','')+'Mid-Joke Laughter Annotations\\\\humanAnnotations.txt'\n",
    "    print(path1)\n",
    "    isExist = os.path.exists(path1) \n",
    "    print(isExist) \n",
    "    \n",
    "    humanRateDict=humanAnnotation(r''+path1)\n",
    "    jokeNameDict=getJokeNameForEachPerformance(path2)\n",
    "    #i am using directory pitch_inten_avg_std_minmax since it is the test contain most information\n",
    "    combine_joke_dict=findAlltxtAndCombine(path3)\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "#     for x in combine_joke_dict:\n",
    "#         for joke in combine_joke_dict[x]:\n",
    "#             print(joke.performance,joke.id)\n",
    "#             print(joke.intensityRange,joke.pitchRange)\n",
    "    \n",
    "#     for x in combine_joke_dict:\n",
    "#         for joke in combine_joke_dict[x]:\n",
    "#             print(joke.performance,joke.id)\n",
    "    #print(len(combine_joke_dict))\n",
    "#     for x in combine_joke_dict:\n",
    "#         clusterDataIn2D(combine_joke_dict[x],1)\n",
    "#     for x in combine_joke_dict:\n",
    "#         clusterDataIn4D(combine_joke_dict[x])\n",
    "#     for x in combine_joke_dict:\n",
    "#         clusterDataIn8D(combine_joke_dict[x])\n",
    "#     overallCorrelation(combine_joke_dict)\n",
    "#     jokeWiseCorrelation(combine_joke_dict)\n",
    "#     overallBoxPlot(combine_joke_dict)\n",
    "#     jokeWiseBoxPlot(combine_joke_dict)\n",
    "\n",
    "    over_all_model_test(combine_joke_dict)\n",
    "    recordBadClassification()\n",
    "    \n",
    "    os.chdir(cwd)    \n",
    "    rbf_df=pd.DataFrame(rbfData,columns=['Performance','JokeId','Joke','HumanScore','PredictScore'])\n",
    "    rbf_df.to_csv (r'.\\mid-joke-GroundTruth.csv', index = False, header=True)\n",
    "\n",
    "#     txtName=\"./jokeoutput/jokewise_all_models/result.txt\"\n",
    "#     if os.path.isfile(txtName):\n",
    "#             os.remove(txtName) \n",
    "#     for name in combine_joke_dict:\n",
    "#         jokewise_model_test(combine_joke_dict[name])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "main()\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
